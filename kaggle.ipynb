{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dce5985b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup:\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "44b25430",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv('/Users/sanzhar123/Downloads/test.csv')\n",
    "training_set = pd.read_csv('/Users/sanzhar123/Downloads/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a8003590",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = None\n",
    "stdevs = None\n",
    "\n",
    "# Define preprocessing transform\n",
    "def conversion_transform(df, is_test = False):\n",
    "    # drop text columns\n",
    "    new_df = df.drop(columns=['track_href', 'uri', 'type', 'analysis_url'])\n",
    "\n",
    "    if is_test == True:\n",
    "        new_df = new_df.drop(columns=['ID'])\n",
    "\n",
    "    # Handle dates \n",
    "    date_column = new_df[\"track_album_release_date\"].astype(str)\n",
    "\n",
    "    parsed = pd.to_datetime(date_column, format='%Y-%m-%d', errors='coerce')\n",
    "    new_df[\"year\"] = parsed.dt.year\n",
    "    new_df[\"month\"] = parsed.dt.month\n",
    "    new_df[\"day\"] = parsed.dt.day\n",
    "\n",
    "    # For year-only dates, extract year and default month/day to 1\n",
    "    year_only_mask = new_df[\"year\"].isna()\n",
    "    new_df.loc[year_only_mask, \"year\"] = pd.to_numeric(date_column[year_only_mask], errors='coerce')\n",
    "    new_df.loc[year_only_mask, \"month\"] = 1\n",
    "    new_df.loc[year_only_mask, \"day\"] = 1\n",
    "\n",
    "    new_df = new_df.drop(columns='track_album_release_date')\n",
    "\n",
    "    if is_test == False:\n",
    "        # Binarization of the output\n",
    "        column_names = list(new_df.columns.values)\n",
    "        column_names.append(column_names.pop(column_names.index('Popularity_Type')))\n",
    "        new_df = new_df[column_names]\n",
    "\n",
    "        lb = LabelBinarizer()\n",
    "        new_df['Popularity_Type'] = lb.fit_transform(new_df['Popularity_Type'])\n",
    "\n",
    "    # replace all the nan values with zero\n",
    "    new_df = new_df.fillna(0)\n",
    "\n",
    "    return new_df\n",
    "\n",
    "def normalization_transform(df, is_test = False):\n",
    "    # normalize data\n",
    "    new_df = df.copy()\n",
    "    if is_test == False:\n",
    "        new_df.iloc[:, :-1] -= means\n",
    "        new_df.iloc[:, :-1] /= stdevs\n",
    "    else: \n",
    "        new_df = new_df[feature_columns]\n",
    "        new_df -= means\n",
    "        new_df /= stdevs\n",
    "    return new_df\n",
    "\n",
    "def preprocessing(df, is_test= False):\n",
    "    new_df = conversion_transform(df, is_test)\n",
    "    new_df = normalization_transform(new_df, is_test)\n",
    "    return new_df\n",
    "\n",
    "# compute normalization mean and stdev\n",
    "filtered_training = conversion_transform(training_set)\n",
    "means = np.mean(filtered_training.iloc[:, :-1], axis=0)\n",
    "stdevs = np.std(filtered_training.iloc[:, :-1], axis=0)\n",
    "feature_columns = list(filtered_training.columns[:-1])\n",
    "\n",
    "filtered_training = preprocessing(training_set)\n",
    "\n",
    "# Save IDs\n",
    "test_IDs = test_set['ID'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e705b830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print((stdevs == 0).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d58fa15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Music Dataloader\n",
    "class MusicDataset(Dataset):\n",
    "    \"\"\"Music dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, dataset, is_test, transform=None):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            dataset: Pandas dataframe\n",
    "            transform: Transformation to data\n",
    "        \"\"\"\n",
    "\n",
    "        data = dataset\n",
    "        if transform:\n",
    "            data = transform(dataset, is_test)\n",
    "\n",
    "        # If it's the test set, there are no labels \n",
    "        if is_test:\n",
    "            self.X = torch.tensor( data.values, dtype=torch.float32)\n",
    "            self.y = None\n",
    "\n",
    "        else:\n",
    "        # example: last column is label, rest are features\n",
    "            self.X = torch.tensor(\n",
    "                data.iloc[:, :-1].values,\n",
    "                dtype=torch.float32\n",
    "            )\n",
    "            self.y = torch.tensor(\n",
    "                data.iloc[:, -1].values,\n",
    "                dtype=torch.long\n",
    "            )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4fa5ff3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = filtered_training.shape[1]-1\n",
    "model1 = nn.Sequential(\n",
    "    nn.Linear(num_features, 256),\n",
    "    nn.GELU(),\n",
    "    nn.Dropout(0.25),\n",
    "\n",
    "    nn.Linear(256, 128),\n",
    "    nn.GELU(),\n",
    "    nn.Dropout(0.25),\n",
    "\n",
    "    nn.Linear(128, 32),\n",
    "    nn.GELU(),\n",
    "    nn.Dropout(0.25),\n",
    "\n",
    "    nn.Linear(32,1),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "38ca72a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model1.parameters(), lr=5*1e-4)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4fafe8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "training_data_loader = DataLoader(MusicDataset(training_set, is_test=False, transform=preprocessing), batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "57221191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataset):\n",
    "    # Switch to the evaluation mode: \n",
    "    model.eval()\n",
    "\n",
    "    # Compute the predictions and compare to the true labels\n",
    "    pred = torch.round(model(dataset.X))\n",
    "    correct = (pred.flatten() == dataset.y).float()\n",
    "    model.train() \n",
    "    \n",
    "    return correct.mean().item() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4b1d3670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1  Loss: 0.4550\n",
      "Accuracy on the training set is 0.6896997690200806\n",
      "Train Epoch: 2  Loss: 0.4879\n",
      "Accuracy on the training set is 0.7160972952842712\n",
      "Train Epoch: 3  Loss: 0.5079\n",
      "Accuracy on the training set is 0.7360248565673828\n",
      "Train Epoch: 4  Loss: 0.5181\n",
      "Accuracy on the training set is 0.7437888383865356\n",
      "Train Epoch: 5  Loss: 0.4369\n",
      "Accuracy on the training set is 0.7479296326637268\n",
      "Train Epoch: 6  Loss: 0.4899\n",
      "Accuracy on the training set is 0.7440476417541504\n",
      "Train Epoch: 7  Loss: 0.6677\n",
      "Accuracy on the training set is 0.7406832575798035\n",
      "Train Epoch: 8  Loss: 0.4133\n",
      "Accuracy on the training set is 0.751035213470459\n",
      "Train Epoch: 9  Loss: 0.4074\n",
      "Accuracy on the training set is 0.7531055808067322\n",
      "Train Epoch: 10  Loss: 0.6059\n",
      "Accuracy on the training set is 0.7549172043800354\n",
      "Train Epoch: 11  Loss: 0.5098\n",
      "Accuracy on the training set is 0.7567287683486938\n",
      "Train Epoch: 12  Loss: 0.5273\n",
      "Accuracy on the training set is 0.7580227851867676\n",
      "Train Epoch: 13  Loss: 0.6146\n",
      "Accuracy on the training set is 0.7611283659934998\n",
      "Train Epoch: 14  Loss: 0.4298\n",
      "Accuracy on the training set is 0.759834349155426\n",
      "Train Epoch: 15  Loss: 0.5702\n",
      "Accuracy on the training set is 0.7556935548782349\n",
      "Train Epoch: 16  Loss: 0.3954\n",
      "Accuracy on the training set is 0.7660455703735352\n",
      "Train Epoch: 17  Loss: 0.6028\n",
      "Accuracy on the training set is 0.7665631175041199\n",
      "Train Epoch: 18  Loss: 0.4909\n",
      "Accuracy on the training set is 0.7634575366973877\n",
      "Train Epoch: 19  Loss: 0.4523\n",
      "Accuracy on the training set is 0.7673395276069641\n",
      "Train Epoch: 20  Loss: 0.3252\n",
      "Accuracy on the training set is 0.7681159377098083\n",
      "Train Epoch: 21  Loss: 0.3892\n",
      "Accuracy on the training set is 0.7696687579154968\n",
      "Train Epoch: 22  Loss: 0.4437\n",
      "Accuracy on the training set is 0.773809552192688\n",
      "Train Epoch: 23  Loss: 0.3885\n",
      "Accuracy on the training set is 0.7725155353546143\n",
      "Train Epoch: 24  Loss: 0.5428\n",
      "Accuracy on the training set is 0.77173912525177\n",
      "Train Epoch: 25  Loss: 0.3090\n",
      "Accuracy on the training set is 0.7761387228965759\n",
      "Train Epoch: 26  Loss: 0.4440\n",
      "Accuracy on the training set is 0.7761387228965759\n",
      "Train Epoch: 27  Loss: 0.3812\n",
      "Accuracy on the training set is 0.7802795171737671\n",
      "Train Epoch: 28  Loss: 0.4957\n",
      "Accuracy on the training set is 0.7782090902328491\n",
      "Train Epoch: 29  Loss: 0.3416\n",
      "Accuracy on the training set is 0.7766563296318054\n",
      "Train Epoch: 30  Loss: 0.5661\n",
      "Accuracy on the training set is 0.782608687877655\n",
      "Train Epoch: 31  Loss: 0.5947\n",
      "Accuracy on the training set is 0.782608687877655\n",
      "Train Epoch: 32  Loss: 0.3739\n",
      "Accuracy on the training set is 0.7854554653167725\n",
      "Train Epoch: 33  Loss: 0.3755\n",
      "Accuracy on the training set is 0.7875258922576904\n",
      "Train Epoch: 34  Loss: 0.4626\n",
      "Accuracy on the training set is 0.7872670888900757\n",
      "Train Epoch: 35  Loss: 0.3785\n",
      "Accuracy on the training set is 0.7895962595939636\n",
      "Train Epoch: 36  Loss: 0.4361\n",
      "Accuracy on the training set is 0.7893374562263489\n",
      "Train Epoch: 37  Loss: 0.5928\n",
      "Accuracy on the training set is 0.7911490797996521\n",
      "Train Epoch: 38  Loss: 0.5190\n",
      "Accuracy on the training set is 0.792443037033081\n",
      "Train Epoch: 39  Loss: 0.5588\n",
      "Accuracy on the training set is 0.7996894121170044\n",
      "Train Epoch: 40  Loss: 0.5253\n",
      "Accuracy on the training set is 0.7999482154846191\n",
      "Train Epoch: 41  Loss: 0.4730\n",
      "Accuracy on the training set is 0.8007246255874634\n",
      "Train Epoch: 42  Loss: 0.2901\n",
      "Accuracy on the training set is 0.8009834289550781\n",
      "Train Epoch: 43  Loss: 0.4255\n",
      "Accuracy on the training set is 0.808747410774231\n",
      "Train Epoch: 44  Loss: 0.4763\n",
      "Accuracy on the training set is 0.8066770434379578\n",
      "Train Epoch: 45  Loss: 0.4605\n",
      "Accuracy on the training set is 0.8118529915809631\n",
      "Train Epoch: 46  Loss: 0.3141\n",
      "Accuracy on the training set is 0.8082298040390015\n",
      "Train Epoch: 47  Loss: 0.4986\n",
      "Accuracy on the training set is 0.8097826242446899\n",
      "Train Epoch: 48  Loss: 0.3355\n",
      "Accuracy on the training set is 0.8105590343475342\n",
      "Train Epoch: 49  Loss: 0.6056\n",
      "Accuracy on the training set is 0.8131470084190369\n",
      "Train Epoch: 50  Loss: 0.2976\n",
      "Accuracy on the training set is 0.8128882050514221\n",
      "Train Epoch: 51  Loss: 0.4004\n",
      "Accuracy on the training set is 0.8198757767677307\n",
      "Train Epoch: 52  Loss: 0.3480\n",
      "Accuracy on the training set is 0.8211697936058044\n",
      "Train Epoch: 53  Loss: 0.4396\n",
      "Accuracy on the training set is 0.8180641531944275\n",
      "Train Epoch: 54  Loss: 0.3723\n",
      "Accuracy on the training set is 0.8209109902381897\n",
      "Train Epoch: 55  Loss: 0.2832\n",
      "Accuracy on the training set is 0.8214285969734192\n",
      "Train Epoch: 56  Loss: 0.3937\n",
      "Accuracy on the training set is 0.8222049474716187\n",
      "Train Epoch: 57  Loss: 0.2150\n",
      "Accuracy on the training set is 0.8245341777801514\n",
      "Train Epoch: 58  Loss: 0.3299\n",
      "Accuracy on the training set is 0.8214285969734192\n",
      "Train Epoch: 59  Loss: 0.3680\n",
      "Accuracy on the training set is 0.8268633484840393\n",
      "Train Epoch: 60  Loss: 0.4477\n",
      "Accuracy on the training set is 0.8299689292907715\n",
      "Train Epoch: 61  Loss: 0.3984\n",
      "Accuracy on the training set is 0.830486536026001\n",
      "Train Epoch: 62  Loss: 0.4703\n",
      "Accuracy on the training set is 0.8320393562316895\n",
      "Train Epoch: 63  Loss: 0.3558\n",
      "Accuracy on the training set is 0.8278985619544983\n",
      "Train Epoch: 64  Loss: 0.3945\n",
      "Accuracy on the training set is 0.8333333134651184\n",
      "Train Epoch: 65  Loss: 0.5223\n",
      "Accuracy on the training set is 0.8338509202003479\n",
      "Train Epoch: 66  Loss: 0.3874\n",
      "Accuracy on the training set is 0.829451322555542\n",
      "Train Epoch: 67  Loss: 0.2958\n",
      "Accuracy on the training set is 0.8392857313156128\n",
      "Train Epoch: 68  Loss: 0.3727\n",
      "Accuracy on the training set is 0.8374741077423096\n",
      "Train Epoch: 69  Loss: 0.4126\n",
      "Accuracy on the training set is 0.8372153043746948\n",
      "Train Epoch: 70  Loss: 0.4261\n",
      "Accuracy on the training set is 0.8418737053871155\n"
     ]
    }
   ],
   "source": [
    "model1.train()\n",
    "dataset = MusicDataset(training_set, is_test= False, transform=preprocessing)\n",
    "for epoch in range(70):\n",
    "    for batch_idx, (data, target) in enumerate(training_data_loader):\n",
    "        # Erase accumulated gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = model1(data)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = loss_fn(output.squeeze(), target.float())\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Weight update\n",
    "        optimizer.step()\n",
    "\n",
    "    # Track loss each epoch\n",
    "    print('Train Epoch: %d  Loss: %.4f' % (epoch + 1,  loss.item()))\n",
    "    print('Accuracy on the training set is', evaluate(model1, dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6ee6086a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's produce the output on the test_set \n",
    "torch_test = MusicDataset(test_set, is_test=True, transform=preprocessing)\n",
    "\n",
    "model1.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = 1 - model1(torch_test.X).squeeze().numpy() # apparently the predictions are flipped lol\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test_IDs,\n",
    "    'Popularity_Type': predictions\n",
    "})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rydcalc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
