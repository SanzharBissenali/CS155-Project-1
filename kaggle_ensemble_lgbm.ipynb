{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "dce5985b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup:\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.base import clone\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from torchmetrics.classification import BinaryAUROC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44b25430",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv('data/test.csv')\n",
    "training_set = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8003590",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = None\n",
    "stdevs = None\n",
    "\n",
    "# Define preprocessing transform\n",
    "def conversion_transform(df, is_test = False):\n",
    "    # drop text columns\n",
    "    new_df = df.drop(columns=['track_href', 'uri', 'type', 'analysis_url'])\n",
    "\n",
    "    if is_test == True:\n",
    "        new_df = new_df.drop(columns=['ID'])\n",
    "\n",
    "    # Handle dates \n",
    "    date_column = new_df[\"track_album_release_date\"].astype(str)\n",
    "\n",
    "    parsed = pd.to_datetime(date_column, format='%Y-%m-%d', errors='coerce')\n",
    "    new_df[\"year\"] = parsed.dt.year\n",
    "    new_df[\"month\"] = parsed.dt.month\n",
    "    new_df[\"day\"] = parsed.dt.day\n",
    "\n",
    "    # For year-only dates, extract year and default month/day to 1\n",
    "    year_only_mask = new_df[\"year\"].isna()\n",
    "    new_df.loc[year_only_mask, \"year\"] = pd.to_numeric(date_column[year_only_mask], errors='coerce')\n",
    "    new_df.loc[year_only_mask, \"month\"] = np.nan\n",
    "    new_df.loc[year_only_mask, \"day\"] = np.nan\n",
    "\n",
    "    new_df = new_df.drop(columns='track_album_release_date')\n",
    "\n",
    "    if is_test == False:\n",
    "        # Binarization of the output\n",
    "        column_names = list(new_df.columns.values)\n",
    "        column_names.append(column_names.pop(column_names.index('Popularity_Type')))\n",
    "        new_df = new_df[column_names]\n",
    "\n",
    "        new_df['Popularity_Type'] = new_df['Popularity_Type'].map({'High': 1, 'Low': 0})\n",
    "\n",
    "    return new_df\n",
    "\n",
    "def normalization_transform(df, is_test = False):\n",
    "    # normalize data\n",
    "    new_df = df.copy()\n",
    "    if is_test == False:\n",
    "        new_df.iloc[:, :-1] -= means\n",
    "        new_df.iloc[:, :-1] /= stdevs\n",
    "    else: \n",
    "        new_df = new_df[feature_columns]\n",
    "        new_df -= means\n",
    "        new_df /= stdevs\n",
    "    # replace all the nan values with zero\n",
    "    new_df = new_df.fillna(0)\n",
    "    return new_df\n",
    "\n",
    "def preprocessing(df, is_test= False):\n",
    "    new_df = conversion_transform(df, is_test)\n",
    "    new_df = normalization_transform(new_df, is_test)\n",
    "    return new_df\n",
    "\n",
    "# compute normalization mean and stdev\n",
    "filtered_training = conversion_transform(training_set)\n",
    "means = np.nanmean(filtered_training.iloc[:, :-1], axis=0)\n",
    "stdevs = np.nanstd(filtered_training.iloc[:, :-1], axis=0)\n",
    "feature_columns = list(filtered_training.columns[:-1])\n",
    "\n",
    "filtered_training = preprocessing(training_set)\n",
    "\n",
    "# Save IDs\n",
    "test_IDs = test_set['ID'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d58fa15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Music Dataloader\n",
    "class MusicDataset(Dataset):\n",
    "    \"\"\"Music dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, dataset, is_test, transform=None, to_remove=None):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            dataset: Pandas dataframe\n",
    "            transform: Transformation to data\n",
    "        \"\"\"\n",
    "\n",
    "        data = dataset\n",
    "        if transform:\n",
    "            data = transform(dataset, is_test)\n",
    "        if to_remove:\n",
    "            data = data.drop(columns=to_remove)\n",
    "        self.labels = list(data.columns)\n",
    "\n",
    "        # If it's the test set, there are no labels \n",
    "        if is_test:\n",
    "            self.X = torch.tensor( data.values, dtype=torch.float32)\n",
    "            self.y = None\n",
    "\n",
    "        else:\n",
    "        # example: last column is label, rest are features\n",
    "            self.X = torch.tensor(\n",
    "                data.iloc[:, :-1].values,\n",
    "                dtype=torch.float32\n",
    "            )\n",
    "            self.y = torch.tensor(\n",
    "                data.iloc[:, -1].values,\n",
    "                dtype=torch.long\n",
    "            )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "    def __getlabels__(self):\n",
    "        return self.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fa5ff3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = filtered_training.shape[1]-1\n",
    "neuralnet = nn.Sequential(\n",
    "    nn.Linear(num_features, 256),\n",
    "    nn.GELU(),\n",
    "    nn.Dropout(0.25),\n",
    "\n",
    "    nn.Linear(256, 128),\n",
    "    nn.GELU(),\n",
    "    nn.Dropout(0.25),\n",
    "\n",
    "    nn.Linear(128, 32),\n",
    "    nn.GELU(),\n",
    "    nn.Dropout(0.25),\n",
    "\n",
    "    nn.Linear(32,1),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38ca72a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(neuralnet.parameters(), lr=5*1e-4)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6c7cd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split and load the data \n",
    "def split_data(dataset):\n",
    "    train_size = int(len(dataset)*0.8)\n",
    "    test_size = len(dataset) - train_size\n",
    "    split_sizes = [train_size, test_size]\n",
    "    train_dataset, valid_dataset = random_split(dataset, split_sizes, generator=torch.Generator().manual_seed(42))\n",
    "    return train_dataset, valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fafe8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MusicDataset(training_set, is_test=False, transform=preprocessing)\n",
    "train_dataset, valid_dataset = split_data(dataset)\n",
    "training_data_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "validation_data_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57221191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataset):\n",
    "    # Switch to the evaluation mode: \n",
    "    model.eval()\n",
    "    auroc_metric = BinaryAUROC(thresholds=None)\n",
    "\n",
    "    # Compute the predictions and compare to the true labels\n",
    "    pred = model(dataset.dataset.X[dataset.indices])\n",
    "    auroc_metric.update(pred, dataset.dataset.y[dataset.indices])\n",
    "    acc = auroc_metric.compute().numpy().item()\n",
    "    model.train() \n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b1d3670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1  Loss: 0.7309\n",
      "Accuracy on the training set is 0.7686705589294434\n",
      "Accuracy on the testing set is 0.7646705508232117\n",
      "Train Epoch: 2  Loss: 0.4953\n",
      "Accuracy on the training set is 0.7869820594787598\n",
      "Accuracy on the testing set is 0.7838901877403259\n",
      "Train Epoch: 3  Loss: 0.5005\n",
      "Accuracy on the training set is 0.7921167016029358\n",
      "Accuracy on the testing set is 0.7901632189750671\n",
      "Train Epoch: 4  Loss: 0.5938\n",
      "Accuracy on the training set is 0.7992556095123291\n",
      "Accuracy on the testing set is 0.7961545586585999\n",
      "Train Epoch: 5  Loss: 0.6111\n",
      "Accuracy on the training set is 0.8053050637245178\n",
      "Accuracy on the testing set is 0.8003218173980713\n",
      "Train Epoch: 6  Loss: 0.4445\n",
      "Accuracy on the training set is 0.8098213076591492\n",
      "Accuracy on the testing set is 0.8033546209335327\n",
      "Train Epoch: 7  Loss: 0.4757\n",
      "Accuracy on the training set is 0.8145673274993896\n",
      "Accuracy on the testing set is 0.8022719621658325\n",
      "Train Epoch: 8  Loss: 0.4769\n",
      "Accuracy on the training set is 0.8179498910903931\n",
      "Accuracy on the testing set is 0.8049042820930481\n",
      "Train Epoch: 9  Loss: 0.5509\n",
      "Accuracy on the training set is 0.8202600479125977\n",
      "Accuracy on the testing set is 0.8000845909118652\n",
      "Train Epoch: 10  Loss: 0.3944\n",
      "Accuracy on the training set is 0.8232514262199402\n",
      "Accuracy on the testing set is 0.8053788542747498\n",
      "Train Epoch: 11  Loss: 0.4180\n",
      "Accuracy on the training set is 0.8270928859710693\n",
      "Accuracy on the testing set is 0.812949538230896\n",
      "Train Epoch: 12  Loss: 0.6033\n",
      "Accuracy on the training set is 0.8284302353858948\n",
      "Accuracy on the testing set is 0.8109845519065857\n",
      "Train Epoch: 13  Loss: 0.7573\n",
      "Accuracy on the training set is 0.8301501274108887\n",
      "Accuracy on the testing set is 0.8098055124282837\n",
      "Train Epoch: 14  Loss: 0.2413\n",
      "Accuracy on the training set is 0.832091212272644\n",
      "Accuracy on the testing set is 0.8092420101165771\n",
      "Train Epoch: 15  Loss: 0.3967\n",
      "Accuracy on the training set is 0.8357813358306885\n",
      "Accuracy on the testing set is 0.8107991814613342\n",
      "Train Epoch: 16  Loss: 0.3709\n",
      "Accuracy on the training set is 0.8389178514480591\n",
      "Accuracy on the testing set is 0.8151295185089111\n",
      "Train Epoch: 17  Loss: 0.4915\n",
      "Accuracy on the training set is 0.8412183523178101\n",
      "Accuracy on the testing set is 0.8122302293777466\n",
      "Train Epoch: 18  Loss: 0.4582\n",
      "Accuracy on the training set is 0.8416552543640137\n",
      "Accuracy on the testing set is 0.8173688650131226\n",
      "Train Epoch: 19  Loss: 0.3018\n",
      "Accuracy on the training set is 0.8419181108474731\n",
      "Accuracy on the testing set is 0.8132980465888977\n",
      "Train Epoch: 20  Loss: 0.3537\n",
      "Accuracy on the training set is 0.8460952043533325\n",
      "Accuracy on the testing set is 0.8165457844734192\n"
     ]
    }
   ],
   "source": [
    "neuralnet.train()\n",
    "train_error = []\n",
    "test_error = []\n",
    "\n",
    "for epoch in range(20):\n",
    "    for batch_idx, (data, target) in enumerate(training_data_loader):\n",
    "        # Erase accumulated gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = neuralnet(data)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = loss_fn(output.squeeze(), target.float())\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Weight update\n",
    "        optimizer.step()\n",
    "\n",
    "    # Track loss each epoch\n",
    "    print('Train Epoch: %d  Loss: %.4f' % (epoch + 1,  loss.item()))\n",
    "    train_error.append(evaluate(neuralnet, train_dataset))\n",
    "    print('Accuracy on the training set is', evaluate(neuralnet, train_dataset))\n",
    "    test_error.append(evaluate(neuralnet, valid_dataset))\n",
    "    print('Accuracy on the testing set is', evaluate(neuralnet, valid_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3279e199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x78c931e97740>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGiCAYAAADEJZ3cAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABzoklEQVR4nO3de3zO9f/H8cfOs7HNHGZjznKa44achUhyiISKCKW+5Sd9K7466qBUVIqiIeVUTpUUI0TkLOfzYTObMWxjdv78/vhwZbZhs+26tj3vt9t1a9fnen8+1+vTZa6X9+H1tjMMw0BERETEhtlbOwARERGR21HCIiIiIjZPCYuIiIjYPCUsIiIiYvOUsIiIiIjNU8IiIiIiNk8Ji4iIiNg8JSwiIiJi85SwiIiIiM1TwiIiIiI2L0cJy5QpU6hSpQqurq4EBgayfv36W7afM2cODRo0wM3NDV9fXwYPHkx0dLTl9VmzZmFnZ5fhkZCQkJPwREREpJDJdsKyYMECRo4cydixY9m5cyetW7emS5cuhIaGZtp+w4YNDBw4kCFDhrBv3z5+/PFHtm7dytChQ9O18/DwICIiIt3D1dU1Z3clIiIihUq2E5aJEycyZMgQhg4dSu3atfn000/x9/dn6tSpmbb/+++/qVy5MiNGjKBKlSq0atWKZ555hm3btqVrZ2dnR7ly5dI9RERERAAcs9M4KSmJ7du3M3r06HTHO3XqxMaNGzM9p0WLFowdO5bly5fTpUsXoqKiWLhwIV27dk3X7vLly1SqVInU1FQaNmzIO++8Q6NGjbKMJTExkcTERMvztLQ0Lly4QKlSpbCzs8vObYmIiIiVGIZBXFwcfn5+2Nvfoh/FyIbw8HADMP766690x9977z3jnnvuyfK8H3/80ShevLjh6OhoAEb37t2NpKQky+ubNm0yvvvuO2PXrl3Gn3/+afTu3dsoVqyYcfjw4Syv+eabbxqAHnrooYceeuhRCB5hYWG3zEHsDMMwuENnzpyhfPnybNy4kebNm1uOv/fee3z33XccPHgwwzn79++nY8eOvPjii3Tu3JmIiAhefvllmjRpQnBwcKbvk5aWRuPGjWnTpg2ff/55pm1u7mGJiYmhYsWKhIWF4eHhcae3JCIiIlYUGxuLv78/ly5dwtPTM8t22RoSKl26NA4ODkRGRqY7HhUVhY+PT6bnjB8/npYtW/Lyyy8DUL9+fdzd3WndujXvvvsuvr6+Gc6xt7enSZMmHDlyJMtYXFxccHFxyXDcw8NDCYuIiEgBc7vpHNmadOvs7ExgYCAhISHpjoeEhNCiRYtMz4mPj88wJuXg4ABAVp07hmGwa9euTJMZERERKXqy1cMCMGrUKAYMGEBQUBDNmzdn2rRphIaGMnz4cADGjBlDeHg4s2fPBqBbt24MGzaMqVOnWoaERo4cSdOmTfHz8wPg7bff5t5776VGjRrExsby+eefs2vXLr788stcvFUREREpqLKdsPTt25fo6GjGjRtHREQEAQEBLF++nEqVKgEQERGRribLoEGDiIuL44svvuCll17Cy8uL9u3b8+GHH1raXLp0iaeffprIyEg8PT1p1KgRf/75J02bNs2FWxQREZGCLluTbm1ZbGwsnp6exMTEZDmHJTU1leTk5HyOTAorBwcHHB0dtYxeROQu3Mn3N+Sgh6Wgunz5MqdPn85y3oxITlzfbsLZ2dnaoYiIFGpFImFJTU3l9OnTuLm5UaZMGf2LWO6aYRgkJSVx7tw5Tpw4QY0aNW5d8EhERO5KkUhYkpOTMQyDMmXKUKxYMWuHI4VEsWLFcHJy4tSpUyQlJWnvKxGRPFSk/kmonhXJbepVERHJH/rbVkRERGyeEpYipl27dowcOdLaYYiIiGSLEhYbZWdnd8vHoEGDcnTdxYsX88477+RKjBs3bsTBwYEHHnggV64nIiKSlSIx6bYgioiIsPy8YMEC3njjDQ4dOmQ5dvPk4eTkZJycnG57XW9v71yLccaMGbzwwgt88803hIaGUrFixVy7dnbd6f2LiEjBpB4WG1WuXDnLw9PTEzs7O8vzhIQEvLy8+OGHH2jXrh2urq58//33REdH079/fypUqICbmxv16tVj3rx56a5785BQ5cqVef/993nqqacoUaIEFStWZNq0abeN78qVK/zwww88++yzPPTQQ8yaNStDm59//pmgoCBcXV0pXbo0vXr1sryWmJjIK6+8gr+/Py4uLtSoUcOye/esWbPw8vJKd62lS5emmzT91ltv0bBhQ2bMmEHVqlVxcXHBMAx+//13WrVqhZeXF6VKleKhhx7i2LFj6a51+vRp+vXrh7e3N+7u7gQFBbF582ZOnjyJvb0927ZtS9d+8uTJVKpUSTV8RKTI+m1PBM98t43UNOv9PVgkExbDMIhPSrHKIze/9F599VVGjBjBgQMH6Ny5MwkJCQQGBrJs2TL27t3L008/zYABA9i8efMtr/PJJ58QFBTEzp07ee6553j22Wc5ePDgLc9ZsGABNWvWpGbNmjzxxBPMnDkz3b39+uuv9OrVi65du7Jz505Wr15NUFCQ5fWBAwcyf/58Pv/8cw4cOMBXX31F8eLFs3X/R48e5YcffmDRokXs2rULMBOpUaNGsXXrVlavXo29vT0PP/wwaWlpgFlAsG3btpw5c4aff/6Zf/75h1deeYW0tDQqV65Mx44dmTlzZrr3mTlzJoMGDdIqMxEpcq4mpTJm8R6enbODFfvO8sO2MKvFUiSHhK4mp1LnjRVWee/94zrj5pw7/9tHjhyZrtcC4L///a/l5xdeeIHff/+dH3/8kWbNmmV5nQcffJDnnnsOMJOgSZMmsXbtWmrVqpXlOcHBwTzxxBMAPPDAA1y+fJnVq1fTsWNHAN577z369evH22+/bTmnQYMGABw+fJgffviBkJAQS/uqVatm59YBSEpK4rvvvqNMmTKWY717984QZ9myZdm/fz8BAQHMnTuXc+fOsXXrVsvwWPXq1S3thw4dyvDhw5k4cSIuLi78888/7Nq1i8WLF2c7PhGRguxARCwj5u3kSNRl7OxgeNtqPBJYwWrxFMkelsLixh4LMCv6vvfee9SvX59SpUpRvHhxVq5cmW4zyszUr1/f8vP1oaeoqKgs2x86dIgtW7bQr18/ABwdHenbty8zZsywtNm1axcdOnTI9Pxdu3bh4OBA27Ztb3uPt1KpUqV0yQrAsWPHeOyxx6hatSoeHh5UqVIFwPL/YNeuXTRq1CjLuTw9e/bE0dGRJUuWAOY8nfvuu4/KlSvfVawiIgWFYRjM3nSSHl/+xZGoy5Qp4cJ3TzXj1Qdq4eRgvbShSPawFHNyYP+4zlZ779zi7u6e7vknn3zCpEmT+PTTT6lXrx7u7u6MHDmSpKSkW17n5smqdnZ2liGUzAQHB5OSkkL58uUtxwzDwMnJiYsXL1KyZMlbVhS+XbVhe3v7DENnmW1aefP9A3Tr1g1/f3+mT5+On58faWlpBAQEWP4f3O69nZ2dGTBgADNnzqRXr17MnTuXTz/99JbniIgUFhevJPHywt2sOnAWgPtqluHjPg0oVdzFypEV0YTFzs4u14ZlbMn69evp0aOHZagmLS2NI0eOULt27Vx7j5SUFGbPns0nn3xCp06d0r3Wu3dv5syZw/PPP0/9+vVZvXo1gwcPznCNevXqkZaWxrp16yxDQjcqU6YMcXFxXLlyxZKUXJ+jcivR0dEcOHCAr7/+mtatWwOwYcOGdG3q16/PN998w4ULF7LsZRk6dCgBAQFMmTKF5OTkDMNuIiKF0aZj0by4YBeRsQk4O9gzukstBresbDPz9zQkVIhUr16dkJAQNm7cyIEDB3jmmWeIjIzM1fdYtmwZFy9eZMiQIQQEBKR7PPLII5aVPm+++Sbz5s3jzTff5MCBA+zZs4cJEyYA5sqkJ598kqeeeoqlS5dy4sQJ1q5dyw8//ABAs2bNcHNz43//+x9Hjx5l7ty5ma5CulnJkiUpVaoU06ZN4+jRo/zxxx+MGjUqXZv+/ftTrlw5evbsyV9//cXx48dZtGgRmzZtsrSpXbs29957L6+++ir9+/fX/lMiUqilpKbxycpDPPbN30TGJlC1jDuLn2vBU62q2EyyAkpYCpXXX3+dxo0b07lzZ9q1a2f5Ys5NwcHBdOzYEU9Pzwyv9e7dm127drFjxw7atWvHjz/+yM8//0zDhg1p3759utVKU6dO5ZFHHuG5556jVq1aDBs2jCtXrgBmrZjvv/+e5cuXW5Zmv/XWW7eNzd7envnz57N9+3YCAgJ48cUX+eijj9K1cXZ2ZuXKlZQtW5YHH3yQevXq8cEHH+DgkH6obsiQISQlJfHUU0/l4P+SiEjBEHYhnke/3sTkP45iGPBoUAWWvdCKgPIZ/463NjujkBSXiI2NxdPTk5iYGDw8PNK9lpCQwIkTJ6hSpYp21JU78t577zF//nz27Nlzy3b6syUiBdWvuyMYvXg3cQkplHBx5P1e9ejWwC/f47jV9/eNCt9EDpG7cPnyZQ4cOMDkyZNzbQsDERFbEp+Uwrhf9jN/q1lTpVFFLz7v1wh/bzcrR3ZrSlhEbvD8888zb948evbsqeEgESl09p+J5YV5Ozh27gp2dvBcu2qM7HiPVZcr3yklLCI3mDVr1h1N8BURKUgMw+DbjSd5f/lBklLT8PFwYdKjDWlRvbS1Q7tjSlhEREQKsQtXknj5x39YfdAsCNqxdlkmPNIAb3dnK0eWPUpYRERECqmNR88zcsEuouIScXa0Z+yDtRnYvJJNLVe+U0pYRERECpnk1DQmhRxm6rpjGAZUK+PO5P6NqeOX9SocW6eERUREpBAJuxDPC/N2sivsEgD9mvjzRrc6Bb7Ce8GOXkRERCx+/ucMYxfvIS4xhRKujnzQqz5d6/taO6xcoYRFRESkgEhJTSM+OZX4xFSuJKVwNSmVK4kpxCel8uueCBZuPw1AYKWSfNavIRVK2nZtlexQwiIiIpJHUtMMLsUncTE+mUvxScQlpk8yzEcKVxJTuZps/vf6czMxSfm3TVIqSSlpt3w/Ozt44b7qjOhQA8cCUFslO5Sw2KjbzeB+8sknc1wvpHLlyowcOZKRI0feUfv333+f119/nffee4/Ro0fn6D1FRAq65NQ0LsYncfFKMhfjk7gUn8SFaz9fvGImJRfjk9I9j7manCexONjb4e7sgJuzI24uDrg7O+Lt7szwttVoXq1UnryntSlhsVERERGWnxcsWMAbb7zBoUOHLMfycwfhmTNn8sorrzBjxgyrJyxJSUk4Oxes2gEiYvuSUtL442AUR87GcSE+iUvxyVy4ci0piU/i0pVk4hJTcnz9Eq6OlHRzpoSrI+7OjhRzdsDd5VrCcS3xcHd2wM3l+nMzCXFzuek1JwfcXBxwdrAvkEuT74YSFhtVrlw5y8+enp7Y2dmlO/bLL7/w1ltvsW/fPvz8/HjyyScZO3Ysjo7mR/rWW28xY8YMzp49S6lSpXjkkUf4/PPPadeuHadOneLFF1/kxRdfBMwKiFlZt24dV69eZdy4ccyePZs///yTNm3aWF5PS0vjo48+Yvr06YSFheHj48MzzzzD2LFjATh9+jT//e9/WblyJYmJidSuXZsvv/ySZs2aMWjQIC5dusTSpUst1xs5ciS7du1i7dq1ALRr146AgACcnZ2ZPXs2devWZd26dUycOJGZM2dy/PhxvL296datGxMmTKB48eKWa/3111/873//Y+vWrbi4uNC0aVPmz5/PL7/8wosvvsiZM2dwcXGxtO/duzfu7u7Mnj07B5+YiBREp6KvMH9rGD9uC+P85aTbtrezA69iTpR0c6akuzMl3ZzwcnPG290ZLzcnvN2cLc9LujlR0t0Zz2JOBaL0va3LUcIyZcoUPvroIyIiIqhbty6ffvoprVu3zrL9nDlzmDBhAkeOHMHT05MHHniAjz/+mFKlMnZbzZ8/n/79+9OjR490X2S5yjAgOT5vrn07Tm7mn/i7sGLFCp544gk+//xzWrduzbFjx3j66acBePPNN1m4cCGTJk1i/vz51K1bl8jISP755x8AFi9eTIMGDXj66acZNmzYbd8rODiY/v374+TkRP/+/QkODk6XsIwZM4bp06czadIkWrVqRUREBAcPHgTMjQTbtm1L+fLl+fnnnylXrhw7duwgLe3WY7A3+/bbb3n22Wf566+/LMmVvb09n3/+OZUrV+bEiRM899xzvPLKK0yZMgWAXbt20aFDB5566ik+//xzHB0dWbNmDampqfTp04cRI0bw888/06dPHwDOnz/PsmXL+P3337MVm4gUPEkpaaw6cJa5m0PZcPS85XiZEi60u6cMpYq74O1uJiIl3ZwtP3u7OeNRzAkH+6LVs2Ersp2wLFiwgJEjRzJlyhRatmzJ119/TZcuXdi/fz8VK1bM0H7Dhg0MHDiQSZMm0a1bN8LDwxk+fDhDhw5lyZIl6dqeOnWK//73v7dMfnJFcjy8n/9baAPwvzPg7H5Xl7g+l+TJJ58EoGrVqrzzzju88sorvPnmm4SGhlKuXDk6duyIk5MTFStWpGnTpgB4e3vj4OBAiRIl0vXYZCY2NpZFixaxceNGAJ544glatmzJ5MmT8fDwIC4ujs8++4wvvvjCEku1atVo1aoVAHPnzuXcuXNs3boVb29vAKpXr57t+61evToTJkxId+zG+TdVqlThnXfe4dlnn7UkLBMmTCAoKMjyHKBu3bqWnx977DFmzpxpSVjmzJlDhQoVaNeuXbbjE5GCIbPeFDs7aFOjDP2bVqRD7bLqCbFh2f5kJk6cyJAhQxg6dCi1a9fm008/xd/fn6lTp2ba/u+//6Zy5cqMGDGCKlWq0KpVK5555hm2bduWrl1qaiqPP/44b7/9NlWrVs3Z3RQR27dvZ9y4cRQvXtzyGDZsGBEREcTHx9OnTx+uXr1K1apVGTZsGEuWLCElJftjr3PnzqVq1ao0aNAAgIYNG1K1alXmz58PwIEDB0hMTKRDhw6Znr9r1y4aNWpkSVZyKigoKMOxNWvWcP/991O+fHlKlCjBwIEDiY6O5sqVK5b3ziougGHDhrFy5UrCw8MBc57OoEGDityYsEhhl5SSxvI9ETzxzWbafrSWqWuPcf5yEmVKuPD8fdX58+X7+PappjwQUE7Jio3LVg9LUlIS27dvzzDxslOnTpZ/hd+sRYsWjB07luXLl9OlSxeioqJYuHAhXbt2Tddu3LhxlClThiFDhrB+/fps3kY2ObmZPR3W4HT3a+LT0tJ4++236dWrV4bXXF1d8ff359ChQ4SEhLBq1Sqee+45PvroI9atW4eTk9Mdv8+MGTPYt2+fZV7M9fcODg7m6aefvu3E39u9bm9vn2H+THJyxhn17u7pe6ROnTrFgw8+yPDhw3nnnXfw9vZmw4YNDBkyxHL+7d67UaNGNGjQgNmzZ9O5c2f27NnDL7/8cstzRKTgUG9K4ZOthOX8+fOkpqbi4+OT7riPjw+RkZGZntOiRQvmzJlD3759SUhIICUlhe7duzN58mRLm7/++ovg4GB27dp1x7EkJiaSmJhoeR4bG3vnN2Jnd9fDMtbUuHFjDh06dMvhlWLFitG9e3e6d+/Of/7zH2rVqsWePXto3Lgxzs7OpKam3vI99uzZw7Zt21i7dm26HpJLly7Rpk0b9u7dS40aNShWrBirV69m6NChGa5Rv359vvnmGy5cuJBpL0uZMmXYu3dvumO7du26bVK1bds2UlJS+OSTT7C3N//C+eGHHzK89+rVq3n77bezvM7QoUOZNGkS4eHhdOzYEX9//1u+r4jYtlvNTekb5E/fJv74exeeQmpFTY7Sy5u7zQ3DyLIrff/+/YwYMYI33niD7du38/vvv3PixAmGDx8OQFxcHE888QTTp0+ndOnSdxzD+PHj8fT0tDyK0pfNG2+8wezZsy2rhA4cOMCCBQt47bXXAJg1axbBwcHs3buX48eP891331GsWDEqVaoEmHVY/vzzT8LDwzl//nym7xEcHEzTpk1p06YNAQEBlkerVq1o3rw5wcHBuLq68uqrr/LKK68we/Zsjh07xt9//01wcDAA/fv3p1y5cvTs2ZO//vqL48ePs2jRIjZt2gRA+/bt2bZtG7Nnz+bIkSO8+eabGRKYzFSrVo2UlBQmT55sub+vvvoqXZsxY8awdetWnnvuOXbv3s3BgweZOnVquvt9/PHHCQ8PZ/r06Tz11FPZ/yBExCacir7Ch78fpMUHq3luzg42HD2PnR20vacMXz0RyMbR7flv55pKVgo6IxsSExMNBwcHY/HixemOjxgxwmjTpk2m5zzxxBPGI488ku7Y+vXrDcA4c+aMsXPnTgMwHBwcLA87OzvDzs7OcHBwMI4ePZrpdRMSEoyYmBjLIywszACMmJiYDG2vXr1q7N+/37h69Wp2btdmzJw50/D09Ex37PfffzdatGhhFCtWzPDw8DCaNm1qTJs2zTAMw1iyZInRrFkzw8PDw3B3dzfuvfdeY9WqVZZzN23aZNSvX99wcXExMvsjkJiYaJQqVcqYMGFCpvF88sknRunSpY3ExEQjNTXVePfdd41KlSoZTk5ORsWKFY3333/f0vbkyZNG7969DQ8PD8PNzc0ICgoyNm/ebHn9jTfeMHx8fAxPT0/jxRdfNJ5//nmjbdu2ltfbtm1r/N///V+GGCZOnGj4+voaxYoVMzp37mzMnj3bAIyLFy9a2qxdu9Zo0aKF4eLiYnh5eRmdO3dO97phGMaAAQMMb29vIyEhIdN7vZ2C/mdLpKBKTE41ft19xnh8+t9GpVeXWR5B74YYH/1+0AiNvmLtEOUOxcTEZPn9fSM7w7hFEY5MNGvWjMDAwHSrL+rUqUOPHj0YP358hva9e/fG0dGRBQsWWI5t2rSJFi1aEB4ejre3N0ePHk13zmuvvWZZgXLPPffcUaGw2NhYPD09iYmJwcMj/fbZCQkJnDhxgipVquDq6pqd25VC7v7776d27dp8/vnnOTpff7ZE8pfmphQ+t/r+vlG2lzWPGjWKAQMGEBQURPPmzZk2bRqhoaGWIZ4xY8YQHh5uKb7VrVs3hg0bxtSpU+ncuTMRERGMHDmSpk2b4udnLi0OCAhI9x5eXl6ZHhfJLRcuXGDlypX88ccffPHFF9YOR0Ru42hUHBN+P8TK/WctxzQ3pWjJdsLSt29foqOjGTduHBEREQQEBLB8+XLL/IiIiAhCQ0Mt7QcNGkRcXBxffPEFL730El5eXrRv354PP/ww9+5CJJsaN27MxYsX+fDDD6lZs6a1wxGRLETFJjBp1REWbA0lzVBvSlGW7SEhW6UhIbEG/dkSyRuXE1OY9udxpv95nKvJ5qrG++v48OoDNaletoSVo5PclGdDQiIiInklOTWN+VtC+Wz1EcsclUYVvfjfg7VpUvnuilBKwaaERURErM4wDH7fG8mEFYc4cd6sWF2ltDuvdK7JAwHlVIVailbCUkhGv8SG6M+UyN3bcuIC4387wM7QSwCULu7M/3WoQb+mFTVHRSyKRMLi4OAAmFsL3K5ku0h2xMebu35nZ8sDETEdjYrjw98PEXJt5U8xJweGtanK022qUtylSHw9STYUiT8Rjo6OuLm5ce7cOZycnCzl3EVyyjAM4uPjiYqKwsvLy5IUi8jt3bzyx8Hejr5N/BnZoQZlPTR5XTJXJBIWOzs7fH19OXHiBKdOnbJ2OFKIeHl5Ua5cOWuHIVIgXE5MYdq6Y0xff8Ky8qdTHR9eeaAW1csWt3J0YuuKRMIC4OzsTI0aNUhKSrJ2KFJIODk5qWdF5A4kp6Yxb0son606QvQVrfyRnCkyCQuAvb29amWIiOQTwzD4bW8kH9208ufVB2rSua5W/kj2FKmERURE8odW/khuU8IiIiK5Rit/JK/oT4+IiNy1+KQUJq48zIy/Tmjlj+QJJSwiInJX/jx8jv8t2cPpi1eB63v+aOWP5C4lLCIikiMXryTx7q8HWLTjNADlvYrx7sMB3FezrJUjk8JICYuIiGSLYRj8sjuCt3/eR/SVJOzs4MnmlXm5c03cNU9F8oj+ZImIyB07c+kqry/dy+qDUQDc41OcD3rXp3HFklaOTAo7JSwiInJbaWkG328+xYe/HeRKUirODvY83746w9tWw9lRy5Ql7ylhERGRWzpyNo7Ri/ew/dRFAAIrleSDXvWo4VPCypFJUaKERUREMpWUksbUtcf4cs1RklLTcHd2YHSXWjzerBL29qpSK/lLCYuIiGSw/dRFxizezeGzlwHoUKss7/QMwM+rmJUjk6JKCYuIiFhcTkzh4xWH+HbTSQwDSrk781b3ujxU31d7/4hVKWEREREA1hyK4rUlewm/ZBaAeySwAmMfrE1Jd2crRyaihEVEpMiLvpzIuGX7+WnXGQD8vYvx/sP1aF2jjJUjE/mXEhYRkSLKMAyW7gpn3C/7uRifjL0dDGlVhRfvvwc3Z309iG3Rn0gRkSIo7EI8Y5fu5c/D5wCoVa4EEx6pT/0KXtYNTCQLSlhERIqQ1DSDWRtP8vGKQ1xNTsXZ0Z7/61CDp9tUxclBBeDEdilhEREpAqIvJ/L7vkjmbQllb3gsAE2reDO+Vz2qldGuymL7lLCIiBRSF68ksWJfJMt2R7DpeDSpaQYAJVwcGfNgbfo18VcBOCkwlLCIiBQiMfHJrNgfya+7I/jr6HlSriUpAPXKe9K1vi+9GpenbAlXK0Ypkn1KWERECrjYhGRC9p3l1z0RrD9yjuTUf5OUOr4edK3vS9d6vlQu7W7FKEXujhIWEZEC6HJiCqv2n2XZ7gj+PHyOpNQ0y2s1fUrwUH1fHqzvq/kpUmgoYRERKSCuJKbwx8Eolu0+w5pD50hK+TdJqVbGnYfq+/FQfV/toiyFUo7WsE2ZMoUqVarg6upKYGAg69evv2X7OXPm0KBBA9zc3PD19WXw4MFER0dbXl+8eDFBQUF4eXnh7u5Ow4YN+e6773ISmohIoXI1KZXleyJ4bs52At8N4YV5O1mx7yxJKWlUKe3OC+2rs2JkG1aNasuL99+jZEUKrWz3sCxYsICRI0cyZcoUWrZsyddff02XLl3Yv38/FStWzNB+w4YNDBw4kEmTJtGtWzfCw8MZPnw4Q4cOZcmSJQB4e3szduxYatWqhbOzM8uWLWPw4MGULVuWzp073/1diogUIAnJqaw9dI5lu8+w+kAUV5NTLa9V9Hbjofq+dK3vSx1fD21IKEWGnWEYxu2b/atZs2Y0btyYqVOnWo7Vrl2bnj17Mn78+AztP/74Y6ZOncqxY8csxyZPnsyECRMICwvL8n0aN25M165deeedd+4ortjYWDw9PYmJicHDwyMbdyQiYn0x8cmsPRzFqgNR/HHgLFeS/k1SKpQsRtf6vjxUz4+A8kpSpHC50+/vbPWwJCUlsX37dkaPHp3ueKdOndi4cWOm57Ro0YKxY8eyfPlyunTpQlRUFAsXLqRr166ZtjcMgz/++INDhw7x4YcfZhlLYmIiiYmJluexsbHZuRUREasyDINj567wx8GzrDoQxfZTFy11UgD8PF3N1T31/WhQwVNJihR52UpYzp8/T2pqKj4+PumO+/j4EBkZmek5LVq0YM6cOfTt25eEhARSUlLo3r07kydPTtcuJiaG8uXLk5iYiIODA1OmTOH+++/PMpbx48fz9ttvZyd8ERGrSk5NY+uJC2YvysGznIyOT/f6PT7F6VDbh461fWjk76WibiI3yNEqoZszfcMwssz+9+/fz4gRI3jjjTfo3LkzERERvPzyywwfPpzg4GBLuxIlSrBr1y4uX77M6tWrGTVqFFWrVqVdu3aZXnfMmDGMGjXK8jw2NhZ/f/+c3I6ISJ65eCXJMtTz56FzxCWmWF5zcrDj3qql6FCrLB1q++Dv7WbFSEVsW7YSltKlS+Pg4JChNyUqKipDr8t148ePp2XLlrz88ssA1K9fH3d3d1q3bs27776Lr68vAPb29lSvXh2Ahg0bcuDAAcaPH59lwuLi4oKLi0t2whcRyXOGYXA06jKrD0ax+sBZtp+6yA0jPZRyd+a+WmXpWLssrWqUobiLqkuI3Ils/aY4OzsTGBhISEgIDz/8sOV4SEgIPXr0yPSc+Ph4HB3Tv42DgwNg/mJnxTCMdHNURERsVVJKGltOXGDVgbP8cTCK0Avph3pqlStBx9o+tK9dloYVNNQjkhPZTu1HjRrFgAEDCAoKonnz5kybNo3Q0FCGDx8OmEM14eHhzJ49G4Bu3boxbNgwpk6dahkSGjlyJE2bNsXPzw8we2GCgoKoVq0aSUlJLF++nNmzZ6dbiSQiYkuiLyey9tA5Vh88y5+Hz3P5hqEeZwd7mlcrRcfaZWlf24fyXsWsGKlI4ZDthKVv375ER0czbtw4IiIiCAgIYPny5VSqVAmAiIgIQkNDLe0HDRpEXFwcX3zxBS+99BJeXl60b98+3QqgK1eu8Nxzz3H69GmKFStGrVq1+P777+nbt28u3KKIyN2LS0hmZ+gltp28wF/HotkRepEbO4lLF3e5NhelLC2rl8ZdQz0iuSrbdVhsleqwiEhuOnPpKttOXWTbyQtsO3mRg5Gx6eaiANT187BMmK1X3lNDPSI5kCd1WERECqPUNINDkXFsP3WBrScvsv3URcIvXc3QrqK3G0GVS9KksjftapbB11NDPSL5RQmLiBQ58Ukp7Aq7xLaTF9l26iI7T11Mt9wYwMHejrp+HgRV8iaockmCKpWkrIerlSIWESUsIlLoRcUlsP3kxWu9JxfYdyaWlJvGd4q7ONKoohdBlbxpUrkkDfy9NA9FxIbot1FECp1j5y6z5cQFtp68wPZTFzl1U0VZAF9PV4IqexNUqSRBlUtSq5wHDpqDImKzlLCISKFxKT6Jt37ex9JdZ9Idt7ODmj4lLPNPgip7a6mxSAGjhEVECoWV+yL535K9nL+ciL0dNKnsfS05KUmjiiXxLOZk7RBF5C4oYRGRAu1SfBJv/7KfJTvDAahWxp2P+zSgUcWSVo5MRHKTEhYRKbBW7T/LmCV7OBdn9qoMa12VF++/B1cnB2uHJiK5TAmLiBQ4MfHJvP3LPhZf61Wpeq1XpbF6VUQKLSUsIlKgrNp/lv8t2UOUelVEihQlLCJSIMTEJ/P2sn0s3nGtV6W0Ox/1aUBgJfWqiBQFSlhExOb9cfAsYxbv4WxsInbXelVGqVdFpEhRwiIiNismPplxy/azaMdpQL0qIkWZEhYRsUk396oMbVWFlzrVVK+KSBGlhEVEbErM1WTeWbafhdvNXpUqpd356JH6BFX2tnJkImJNSlhExGasORTFmEV7iIxNwM4OhrQ0e1WKOatXRaSoU8IiIlYXczWZd5ft50f1qohIFpSwiIhV3dyr8lTLKvxXvSoichMlLCJiFbEJZq/KD9vMXpXKpdz4qE8DmqhXRUQyoYRFRPLdmkNR/G/xHiJizF6VwS2q8HJn9aqISNaUsIhIvtkVdomPVxxiw9HzgNmrMuGRBjStol4VEbk1JSwikucORMTyycrDrDpwFgAnBzsGNq+suSoicseUsIhInjl+7jKTVh1h2e4zGAbY20GvxhX4vw418Pd2s3Z4IlKAKGERkVwXfukqn686wsIdp0lNMwDoWs+XF++/h+pli1s5OhEpiJSwiEiuiYpLYMqaY8zdHEpSahoA7WuVZdT99xBQ3tPK0YlIQaaERUTu2qX4JL5ad5xvN57kanIqAM2rluK/ne8hsJIm1IrI3VPCIiI5djkxhRkbTjD9z+PEJaYA0NDfi5c716Rl9dJWjk5EChMlLCKSbQnJqXy36RRT1x3jwpUkAGqVK8F/O9WkQ+2y2NnZWTlCESlslLCIyB1LSknjh21hTP7jCGdjEwFz358X77+Hh+r5Ym+vREVE8oYSFhG5rdQ0g6U7w/l09WHCLlwFoLxXMf6vQw16NS6Po4O9lSMUkcIuR3/LTJkyhSpVquDq6kpgYCDr16+/Zfs5c+bQoEED3Nzc8PX1ZfDgwURHR1tenz59Oq1bt6ZkyZKULFmSjh07smXLlpyEJiK5KC3NYPmeCDp/+icv/fgPYReuUrq4C291q8Mf/23Lo038layISL7I9t80CxYsYOTIkYwdO5adO3fSunVrunTpQmhoaKbtN2zYwMCBAxkyZAj79u3jxx9/ZOvWrQwdOtTSZu3atfTv3581a9awadMmKlasSKdOnQgPD8/5nYlIjhmGwZpDUXT/cgPPzdnB0ajLeBZz4tUHavHnK+0Y1LIKLo6qUCsi+cfOMAwjOyc0a9aMxo0bM3XqVMux2rVr07NnT8aPH5+h/ccff8zUqVM5duyY5djkyZOZMGECYWFhmb5HamoqJUuW5IsvvmDgwIF3FFdsbCyenp7ExMTg4eGRnVsSkWvik1L45Z8zzNkcyu7TMQC4OzswpHVVhraugoerk5UjFJHC5k6/v7M1hyUpKYnt27czevTodMc7derExo0bMz2nRYsWjB07luXLl9OlSxeioqJYuHAhXbt2zfJ94uPjSU5Oxts76/oNiYmJJCYmWp7HxsZm51ZE5Ab7z8Qyb0soS3eGW5Ynuzja82SLygxvWw1vd2crRygiRV22Epbz58+TmpqKj49PuuM+Pj5ERkZmek6LFi2YM2cOffv2JSEhgZSUFLp3787kyZOzfJ/Ro0dTvnx5OnbsmGWb8ePH8/bbb2cnfBG5wdWkVH7ZfYa5m0PZFXbJcrxSKTf6N63II4EVKF3cxXoBiojcIEerhG6usWAYRpZ1F/bv38+IESN444036Ny5MxEREbz88ssMHz6c4ODgDO0nTJjAvHnzWLt2La6urlnGMGbMGEaNGmV5Hhsbi7+/f05uR6RIORgZy7zNoSzeGU5cgtmb4mhvR+e65XisWUWaVy2l5ckiYnOylbCULl0aBweHDL0pUVFRGXpdrhs/fjwtW7bk5ZdfBqB+/fq4u7vTunVr3n33XXx9fS1tP/74Y95//31WrVpF/fr1bxmLi4sLLi7615/InUhITmXZ7gjmbj7FjtBLluMVvd3o19SfPoH+lCmh3ycRsV3ZSlicnZ0JDAwkJCSEhx9+2HI8JCSEHj16ZHpOfHw8jo7p38bBwVxdcON8348++oh3332XFStWEBQUlJ2wRCQLR87GMWdzKIt3nCb2ht6U++v48FizirSsVlq9KSJSIGR7SGjUqFEMGDCAoKAgmjdvzrRp0wgNDWX48OGAOVQTHh7O7NmzAejWrRvDhg1j6tSpliGhkSNH0rRpU/z8/ABzGOj1119n7ty5VK5c2dKDU7x4cYoX11b0ItmRkJzK8j0RzNsSytaTFy3HK5QsRv+mFekTWIGyHlkPt4qI2KJsJyx9+/YlOjqacePGERERQUBAAMuXL6dSpUoAREREpKvJMmjQIOLi4vjiiy946aWX8PLyon379nz44YeWNlOmTCEpKYlHHnkk3Xu9+eabvPXWWzm8NZGi5WhUHHM3h7Fox2liriYD4GBvR8faZenftCJtapRRb4qIFFjZrsNiq1SHRYqihORUft8bydwtoWw5ccFyvLxXMfo18efRJv74qDdFRGxYntRhERHbEBFzleD1J1i04zQX483eFHs7aF/Lh8ebVaTNPWVwUG+KiBQiSlhECpCE5FS+WX+cL9cc42pyKgC+nq70beJP3yb++HoWs3KEIiJ5QwmLSAFgGAarDkTxzrL9hF6IByCoUkmebVeNdjXLqjdFpCAwDMiiZpncnhIWERt37Nxlxv2yn3WHzwHg4+HC/x6sTfcGflkWbBQRG3NgGfwyAio2h4c+heJlrB1RgaOERcRGXU5MYfLqI8z46wTJqQZODnYMbV2V5++rjruLfnVFCoytwbD8v2CkwcFlELYZekyBezpZO7ICRX/ridiYtDSDpbvCGf/bQc7FmRt8tq9VltcfqkOV0u5Wjk5E7phhwJr34M+PzOf1HoWzeyFqP8ztA02Gwv3vgLObdeO8U1Ye0lLCImJD9obH8MZPey3l8yuXcuONbnVoXyvzrS9ExEalJsOykbDze/N5uzHQ9lVISYRVb8HmqbD1GzixHnpPB98G1oz21lJTYOds2LMIBi4FByerhKGERcQGXLiSxEcrDjF/ayiGAW7ODjzfvjpDWlXBxdHB2uGJSHYkXYEfB8GRlWBnDw9NgsBB5mtOrtDlA6hxPyx9Fs4fgukdoMPr0PwFsLe3ZuQZHV0NK8bCuQPm890LoNETVglFheNErCglNY05m0P5ZOUhy14/PRr6MaZLbcp5quCbSIFz5TzM6QNndoBjMegzE2p2yaJttDkR9+Ay83nl1vDwV+BZIf/izUrUQVj5GhwNMZ8XK2n2EgU9les9LHf6/a2ERcRKNh2L5u1f9nEwMg6AOr4evN2jLk0qe1s5MhHJkQvH4fve5n+LecNjP4B/k1ufYxiwYzb8PhqS48HV01xFFNArX0LO4Eo0rH0fts0EIxXsHaHpM9D2ZTNpyQOqdCtio85cusp7yw/w6+4IALzcnHipU00ea1pR9VRECqozO82elSvnwKsiPLEYSte4/Xl2dhD4JFRuBYuGmj0zCwfDkRDo8iG45tM/wFMSYfPX8OfHkBhjHqvZFTq9A6Wq5U8Mt6EeFpF8cnOVWns7eKxZRV66vyYl3Z2tHZ6I5NTRVbBgICRfgXL14PGFUKJc9q+TmgxrP4ANE80l0F6VoNd0qNgs92O+zjDgwC8Q8gZcPGEeK1cPOr8PVdrk3fveQENCIjYisyq1TSt782b3OtT187RydCIFRFoqbJwMoZugyTCo3sE2qsbumgc/Pw9pKVC1HTz63d33ipzaBIufhphQc9Jum5ehzSvgkMuDImd2mhNqT/1lPi/uAx3egAb9wT7/JvsrYRGxAapSK5ILLp+DxcPg+Jp/j1VoYk4CrdbeOomLYcCGSbD6bfN5vT5mMTjHXOotTYiB5S+bq3IAygeZy5+9q979tWPPwOpx8M8887mjK7QYAS3/D1yK3/31sxuOEhYR60lITmVSyGFLlVpnB3uGtK6iKrUi2XVyAywcApcjzVU3dXrA/qWQkmC+7n8vtBtt9m7kV+KSlgq/vQpbp5vPW4yAjm/nzZLkPQth2ShzXolzcXNeS8PHc3avSVfgr8/hr88g5ap5rH5fs1fFiiuTlLCIWMnZ2ASenr2Nf06bE9c61CrLa6pSK5I9aWnmXI4175nzOUrXhEe/hbK1IS4SNnwK22ZAqlkNmoot4L4xeT/vIjkBFg81531gBw+Mh3ufzdv3vBQGS4bDqQ3m89rdodtn4HaHKwrT0mD3fLNXJc6c7I//veY8lQqBeRNzNihhEbGCf8Iu8fR32zgbm4iXmxMfP9KAjnVUpVYkW65Ew5KnzcmsAPX7QddPMg5XxEaYwzLbZ/2buFRqZSYulVvlflxXL8K8xyB0Izg4w8Nf59/y47RUs2dkzXvmfJkSvtBzKlS779bnnfwLVoyBiH/M514V4f5xUKenbcwBQgmLtcORIuinXeG8snA3iSlp1ChbnG+eDKJSKfWqiGRL6N/w42CIO2POrXjwI2g04NZfrrFnYP1E2PEtpCaZxyq3hvv+B5Va5E5cMafNGivnDoKLB/SbC1Va5861s+PMTlg0DKKPmM+bP28O6Ti6pG934bi58ufAL+Zz5xLQ5r/QbLhZbdeGKGERySdpaQafhBziyzXHAHMI6NN+DSnhap39NkQKpLQ02Pi5OWxhpEKpGuYQkE/dO79GzOlrictsSEs2j1VpayYuFe/NeWxn98H3j5hJVAlfeGJR9uLKbUlXzCq022aYz33qmRNyy9aGq5fMzRY3f23+P7CzN7cFaPc/KF7GejHfghIWkXxwOTGFFxfsImT/WQCGt63Gy51rqgCcSHbEXzDnaBxZYT6v18fcf8elRM6udykM1n9ibjx4PXGpep+ZuPg3zd61Tm4wh4ESY8x5NE8sAi//nMWV2w79Bj89D/Hnzd6oRk/A3sVw9YL5erX20Ok98Klj3ThvQwmLSB4LuxDP0G+3cehsHM6O9nzYux4PN7KBPUBECpKwLeYQUOxpcHAxV8EEDsqd+RWXQs3KrbvmmPM+AKp1MBOXCkG3P3/fErMeSmqSOUm1/7w7n+iaX+LOwk/P/TvfB8zEqvN75gaLBYASFpE8tPl4NM/O2cGFK0mUKeHCtAGBNKqYN/tsSDZFHYCVr5v/qqzbC3wb2MzkQrmBYcCmL2DVW2Yy4V3NHAIqVy/33+viyWuJy1xzuAmg+v3m5NzyWayS+fsrc38fDKj1EPT+BpyK5X5sucEwYOs3Zl2VBv0hcHDuF5nLQ0pYRPLIvC2hvL50LylpBgHlPZg+MAhfTxv9i6yoSYiBae3MCYfXeVczV3IE9DbH+MX64i/A0ufg8G/m87q9zGW6eb1vzoUTZuLyz7x/E5canc3Exa+R+TwtDVa/Za7IAWgyFLpMyNfKr0WNEhaRXJaSmsa7vx5g1saTADxU35ePHmlAMWf9RWYTDAN+fBL2/wQeFcz6EodX/FtgDKBMbTN5qdsLSle3XqxF2elt5hBQTKi5NPiB8RA0JH97waKPmYnL7vlmjReAe7qYq2g2fw17fjCPtX8dWr+kHro8poRFJBfFxCfzn7k72HD0PAAv3X8Pz7evrvL6tuTvr+D3V8HeCZ763ZyjkBgHh36HfYvN3W+vT8AEKFff7HWp+zCUrGS9uIsKw4C/p5pLbdOSoWQVcwjIt4H1Yoo+BusmmAnK9cQFwM4Buk+GRo9bL7YiRAmLSC45GnWZYbO3ceL8FdycHZj4aEMeCMjBTqySd05vgxkPmF+ED3yQeeXRq5fg4K9m8nJszb9DAmDuS1O3F9TtCR5++RV10XH1orma5eAy83mdHmZC4Gojm3+ePwLrPjTL4Du5waOzoUZHa0dVZChhEckFaw9F8cK8ncQlpFDeqxjTBwZRx09/vmxK/AX4ug3EhJklyx+dffsu/CvRcOBn2LvIXLbK9b8G7cxCYwG9oHYPm61bUaCEb4cfB5krdhyczWW2TYfZ5jDLpTCwdwQPX2tHUqQoYRG5C4ZhELzhBO8vP0CaAU0ql2TqE4GULu5y+5Ml/6Slwby+cGSluYvt02uz/6/2uEhz3svexRD297/H7ezNomMBvcxVIra2nNXWGQZsmQYrxpo9X16VoM8sKN/Y2pGJjVHCIpJDiSmpvLZkLz9uPw3Ao0EVeKdnAC6Omlxrc9ZPhNVvm/U7hq4C3/p3d72Y02btjb2L4cyOf4/bO5lFuAJ6Qc0H8341S0GXEGMOAR342Xxe6yHo8SUU87JqWGKblLCI5MC5uESe/X47205dxN4OXutah8EtK2tyrS06uQG+7WZOluz2mVlsLDddOP5v8nJ277/HHVygegfwb2YuhfVraDtzMWzBmV3maq2LJ81Er9M75v41+h2SLNzp97d9Ti4+ZcoUqlSpgqurK4GBgaxfv/6W7efMmUODBg1wc3PD19eXwYMHEx0dbXl937599O7dm8qVzS+GTz/9NCdhidyVfWdi6PHFBradukgJV0dmDm7KU62qKFmxRZejYOEQM1mp3w8aP5n77+Fd1VzS+uxf8J8t0HY0lL7H3BX40HJY9SbM7g4fVITJgeaGdJummJv3JV3J/Xhs2YXjsDUY5j8OwfebyYpnRXhqhTkBWr9DkguyXQpvwYIFjBw5kilTptCyZUu+/vprunTpwv79+6lYsWKG9hs2bGDgwIFMmjSJbt26ER4ezvDhwxk6dChLliwBID4+nqpVq9KnTx9efPHFu78rkWz6fW8ELy74h6vJqVQp7c43TwZRrUzx258o+S8tFRYNgcuRUKYWPDQx778Qy9Q0i4u1G232thxdZe6ae2anOZk0+qj5uF6/w87erPni1wjKNzL/6xOQcUfdgurqRTjxJxz7w1xxdelU+tdrPgg9p0AxVX+W3JPtIaFmzZrRuHFjpk6dajlWu3Ztevbsyfjx4zO0//jjj5k6dSrHjh2zHJs8eTITJkwgLCwsQ/vKlSszcuRIRo4cmZ2wNCQkOWIYBpP/OMrEkMMAtK5Rmi/6N8bTTTst26w/3oM/J5jLT59eayYT1nTlvDkMcmaHmcCE7zCTqZvZO5k7/Po1Miee+jUyk5qCUEI9JQlObzUTlONrzPu8sW6JvZM5RFatnTnXx6+xelXkjt3p93e2flOSkpLYvn07o0ePTne8U6dObNy4MdNzWrRowdixY1m+fDldunQhKiqKhQsX0rVr1+y8dQaJiYkkJiZansfGxt7V9aTouZqUyn8X/sOvuyMAGNyyMmMfrI2jQ45GSiU/HF0Ff35k/tztM+snKwDupc2aHTfW7YiNSJ/AnNlp7qAbsct8bJ9ptnMsZu6dcz2B8WsMpaqDvZX/DBoGnD9s9p4c+8OcL5R80zBX6ZpmclLtPqjUElzUIyl5K1sJy/nz50lNTcXHxyfdcR8fHyIjM/kXBWbCMmfOHPr27UtCQgIpKSl0796dyZMn5zxqYPz48bz99tt3dQ0pusIuxPPsnO3sDY/FycGOd3sG0LdJxiFNsSEx4ebOuRjm5m71H7V2RFnz8AWPrlDr2j/MDMMcNrkxgTmzC5Li4PQW83GdcwkzEStRznwULwclfNL/17107u9tc+U8HF/77zBP3Jn0r7uVhqrtzCSlajvwLJ+77y9yGznqi7x5EqJhGFlOTNy/fz8jRozgjTfeoHPnzkRERPDyyy8zfPhwgoODc/L2AIwZM4ZRo0ZZnsfGxuLv75/j60nR8efhc4yYv5NL8cl4uzvz1ROBNK2iGhs2LTUZFg6G+GizpP4DH1g7ouyxs4OSlc1H3YfNY2lpcOHYDQnMDojYbSYx4dtucz0HcC+TMZEp4QMlfP/92b0sODpnfo3kBAjd9O8wT+Se9K87uECl5lD1PjNJ8Qmwfs+PFGnZSlhKly6Ng4NDht6UqKioDL0u140fP56WLVvy8ssvA1C/fn3c3d1p3bo17777Lr6+Oaso6OLigotLIZnAJvkiLc1g6rpjfLzyEIYB9St4MvWJQMp7aadlm7fqLQjbDC4e5v4zTq7Wjuju2dtD6Rrmo0Ff81hqCpw7aK66uXzWLGp3ORLizv773yvnzG0FLl97jX9u/T5upW7qnSkFkXvNZOXGjSEBfOr9Ow+lYnNw0u+G2I5sJSzOzs4EBgYSEhLCww8/bDkeEhJCjx49Mj0nPj4eR8f0b+PgYHZlFpISMFIAxCYk89IP/xCy/ywA/Zr481b3urg6qRiczTv4K2z6wvy5x5fmcuPCysERygWYj6ykpphJy+VIM6GJi7whubnhv5fPQlqK2SsVHw1R+zJeq3i5f+ehVG0Hxcvm2a2J3K1sDwmNGjWKAQMGEBQURPPmzZk2bRqhoaEMHz4cMIdqwsPDmT17NgDdunVj2LBhTJ061TIkNHLkSJo2bYqfn7nJWFJSEvv377f8HB4ezq5duyhevDjVq2sLeLk7h8/GMfy77Rw/fwVnB3ve7lGX/k01X6VAuHACllzbyPDe/0Cd7taNxxY4XNvr5nb73aSlmRN9b+6luXwOvCqaSUqZWlrNIwVGjirdTpkyhQkTJhAREUFAQACTJk2iTZs2AAwaNIiTJ0+ydu1aS/vJkyfz1VdfceLECby8vGjfvj0ffvgh5cubk7ZOnjxJlSpVMrxP27Zt013nVrSsWTKzbPcZXlm4m/ikVPw8XZnyRCAN/b2sHZbcieQEmNEJIv4xd1MetDzr+RgiUmCpNL8UaSmpaXzw20G+2XACgBbVSjG5fyNKafPCgmPZKNgWbBYfe2Y9eGlSvUhhlCd1WEQKgnNxiTw/dwebT1wA4Jm2VXm5U03VVylI9iw0kxWAXtOVrIiIEhYpXHaEXuS573cQGZuAu7MDH/dpQJd6OVuJJlZy7jD8PML8ufVLUON+68YjIjZBCYsUCoZh8P3mUMb9so/kVINqZdz5ekAg1cuWsHZokh1J8fDDQLOqauXW0O5/1o5IRGyEEhYp8BKSUxm7ZC+LdpwGoEtAOT7q04DiLvrjXaAYBvz6Epw7YBY86/1NwdhnR0Tyhf42kAIt7EI8w7/fzr4zsdjbwasP1OLpNlWzrLwsNmzn9/DPXHOn40eCzbL0IiLXKGGRAmvd4XP83w0l9r/o34gW1UtbOyzJicg9sPy/5s/3/Q+qtLFuPCJic5SwSIGTlmYwZe1RPgk5jGFAA38vpj7eGD+V2C+YEmLhhyfNMvHVO0Krl6wdkYjYICUsUqDEJiQzasE/rDpgltjv37Qib3Wvg4ujSuwXSIYBP79gbgLoUR4enqYN9kQkU0pYpMA4FBnH8O+3c+L8FZwd7Xm3RwCPNlF9jgJty3TYvxTsHaHPLHNjPhGRTChhkQLhl3/MEvtXk1Mp71WMqU80pn4FL2uHJXfj9HZYcW3Z8v3jwL+pdeMREZumhEVsWvK1EvvB10rst6pems/7N8LbXXvKFGjxF+DHQZCWDLUegnufs3ZEImLjlLCIzToXl8h/5u5gy7US+8+1q8ZLnWriYK8lywVaWiosfRZiQqFkZejxpXYMFpHbUsIiNulsbAKPfr2JU9HxFHdx5OM+DXggQHU5CryURFg8DA7/Dg4u0OdbKOZl7ahEpABQwiI258KVJJ74ZjOnouPx9y7GrMFNqVamuLXDsh1paXB0FZzeAk2GQQkfa0d0ZxLjYP7jcGId2DtB7+ng19DaUYlIAaGERWxKzNVkBgRv5kjUZcp5uDJ36L34e7tZOyzbkJIEe36EjZPN8vUAu+ZC//ngW9+6sd3OlWiY8wic2QFO7tBvDlS7z9pRiUgBooRFbEZ8UgpPzdrKvjOxlC7uzJxhzZSsACTEwLaZsPkriIswjzmXgGIlzXkgMx4weytqdbVunFmJOQ3fPQznD0Mxb3h8IVQItHZUIlLAKGERm5CQnMqw2dvYfuoiHq6OzH6qmYaBYsJh81TYNguS4sxjJXyh2XAIGmwWXftxEBxfYw61dHwTWo60rQms5w6byUrsabMw3IAlUKamtaMSkQJICYtYXXJqGs/P3cFfR6Nxd3bg26eaUsfPw9phWc/Zfeawz54fIS3FPFamFrR4Aer1AUeXf9s+vhB+Hw1bp8Oqt8wEodun6dtYS/h2+P4RuHoBStUwkxUvFfoTkZxRwiJWlZpm8OKCXaw6EIWLoz3fPNmERhVLWjus/GcYcHI9/PWZOaH2ukqtoOUIqH5/5iXrHRyh68dmr8Vvr5q7HV88AX2/B3crbgR5fK3Z65N0GfwamYmVNeMRkQJPCYtYTVqawZjFu1m2OwInBzu+GhBI82r5WJo9/oK54V4JX+sNo6SmwIGf4K/PIWKXeczOHmp3NxOV8nc416PpMPCuCj8OhtBNMP0+eOwHKFs7z0LP0v6fYNFQSE0yd13uNxdcSuR/HCJSqChhEaswDINxy/bzw7bT2NvB5/0acV/Nsvnz5nGR8OdHsH2WOeTiVgrK1bv2aGD+t1R1s/ciryRdgZ3fw6Yv4dIp85hjMWj0ODT/j5l8ZFf1DjA0BOb2NXtZvrkf+syEGvfnbuy3sn0WLHsRjDQz6er9jW0MT4lIgWdnGIZh7SByQ2xsLJ6ensTExODhUYTnPxQQH684xBdrjgLwSZ8G9A6skPdvevWiOeTy91eQctU8ZmdvfrnezNEVytYxkxff+lCuvvnc5S4nAl8+B1ummXNOrl40j7mVgqZPmzVVcmPzv/gLsGAAnNpg3l+n9+DeZ/O2F8kwYMMkWP22+TxwEHSdCPbaRVtEbu1Ov7+VsEi+m7L2KBN+PwTAOz3qMqB55bx9w6Qr5pLgvz4zlwgDVGgCHd40/xu1HyL3/Ps4u9ece5GBHZSqdq0n5loSU67enRVuiz5mTqT9Z545DAVmWfrmz0PDx8E5l5dvpyTBr6Ng53fm88BB8ODH4OCUu+8DZiG7kNdh0xfm89YvQfvXbWu1kojYLCUsYpO+3XiSN3/eB8DoLrUY3rZa3r1ZShLs+BbWTYArUeaxsnXML9OaXbL+Qk1LM4dUInenT2Su10C5mXvZf4eUrvfGeFc1exfCtsLGz+DAMuDar1r5QGgxAmp3y9seCMMwh5xWvma+d+XW8OhscPPOvfdITYGfXzAn+4LZm9Pi+dy7vogUekpYxOb8uC2MlxfuBmBE++qM6pRH9TjSUs0lwWve/3d+iFcluG8s1Hsk50nC5aj0CUzkbjh/BEsiciMnN3My74Vj/x675wEzUanUIn97Hw79DouGmL1G3tXgsQVQusbdXzf5Kix8Cg4tBzsHcxPDhv3v/roiUqQoYRGb8uvuCF6Yt4M0A55qWYXXH6qNXW5/aRuG+eX5x7vmMA9AcR9o8zI0fhIcnXP3/cAcboo68G9vTMRus47K9Tky9k5Qv69ZQ6Vsrdx//zt1dh/M7WdWxnX1NDcdvJvS+AkxMK8/nPrLnO/TZ5bZayUikk1KWMRm/HHwLE/P3k5KmkG/Jv6M71Uv95OVE3/C6nFweqv53NXTrPra7Blwds/d97qdtFRzzkr0UbMGiYdv/r5/Vi6fg/mPmZsm2jnAgx9BkyE5uE4UfN/LTNBcPMy9jCq3zP14RaRIUMIiNmHj0fMMmrWVpJQ0ujfwY1LfhjjY52KyEr7DTFSOrzGfO7mZpetbjjD32pH0khPglxGwe4H5vOkz0Pn9O1/CffGkWWr/wnFwLwNPLLb9jRdFxKbd6fe36rBIntl+6iJDZ28jKSWN++v48MmjDXIvWTl3GP54Bw78bD63dzJXwrR5+c5W7RRVTq7w8NdQ+h7z/9+Wr82eoD4zzV6pWzm730xWLkeCV0UYsNRcNSUikg+UsEie2Bsew6CZW4hPSqVV9dJM7t8IJ4dMSstn16UwWPuBuSrFSAPszDki940xlwnL7dnZQZv/mhNvFz8Dx1abReYem591wbrQzTC3jzl3pWwds2fFVoa6RKRIyNE3yJQpU6hSpQqurq4EBgayfv36W7afM2cODRo0wM3NDV9fXwYPHkx0dHS6NosWLaJOnTq4uLhQp04dlixZkpPQxAYcjYpj4IwtxCWkEFSpJNMGBuLqdJfLdy+fg99Gw+TGsOt7M1mp2RWe3Qi9vlaykhN1esBTv0MJPzh/CKZ3gJN/ZWx3JARm9zCTFf9mMHi5khURyXfZTlgWLFjAyJEjGTt2LDt37qR169Z06dKF0NDQTNtv2LCBgQMHMmTIEPbt28ePP/7I1q1bGTp0qKXNpk2b6Nu3LwMGDOCff/5hwIABPProo2zevDnndyZWERodz+PfbObClSTqlfdkxuAmuDnfRUdeQgz88R583hA2TzX3p6ncGoasgv5zwadOrsVeJPk1hGF/mJODr14wE5Od3//7+p6FMK+fueqp+v3mMJDmBomIFWR70m2zZs1o3LgxU6dOtRyrXbs2PXv2ZPz48Rnaf/zxx0ydOpVjx/6tRzF58mQmTJhAWFgYAH379iU2NpbffvvN0uaBBx6gZMmSzJs3747i0qRb64uIucqjX28i7MJVapQtzoJnmuPtnsOlxIYB24LNJcrXS9j7NYIOb0DV+1RFNbclxcPSZ2H/UvN5ixfA09/cARoD6j0KPafkTaVcESnS7vT7O1s9LElJSWzfvp1OnTqlO96pUyc2btyY6TktWrTg9OnTLF++HMMwOHv2LAsXLqRr166WNps2bcpwzc6dO2d5TbE95y8n8vg3mwm7cJVKpdyYM7RZzpOVK9FmjY9fXzKTldL3mBVah62Bau2VrOQFZzd4ZCa0fdV8vnEy/PYKYJgriR7+WsmKiFhVtvrqz58/T2pqKj4+6Vdh+Pj4EBkZmek5LVq0YM6cOfTt25eEhARSUlLo3r07kydPtrSJjIzM1jUBEhMTSUxMtDyPjY3Nzq1ILoqJT2ZA8BaOn7uCn6crc4Y2o6yHa84udnwdLH7aXIni4Awd3zY3BszLnZPFZG8P9/3PTBCXPgepiWZ14DYvK0kUEavL0aTbm4t+GYaRZSGw/fv3M2LECN544w22b9/O77//zokTJxg+fHiOrwkwfvx4PD09LQ9/f/+c3IrcpcuJKTw5cwsHImIpXdyF74c2o0LJHGzkl5oMq94251BcjjS/NIf9Ac2fU7KS3+o9As9tgqdWQttXlKyIiE3I1jdB6dKlcXBwyNDzERUVlaGH5Lrx48fTsmVLXn75ZQDq16+Pu7s7rVu35t1338XX15dy5cpl65oAY8aMYdSoUZbnsbGxSlryWUJyKkO/3cqusEt4uTnx/dCmVC1TPPsXunACFg2F8G3m88BB0Hl87u9gLHeuVDXVWBERm5KtHhZnZ2cCAwMJCQlJdzwkJIQWLVpkek58fDz29unfxsHBXOJ6fb5v8+bNM1xz5cqVWV4TwMXFBQ8Pj3QPyT+GYfDSD//w9/ELFHdx5NvBTalVLgefwe4f4avWZrJyfY+bbp8pWRERkXSy3dc+atQoBgwYQFBQEM2bN2fatGmEhoZahnjGjBlDeHg4s2fPBqBbt24MGzaMqVOn0rlzZyIiIhg5ciRNmzbFz88PgP/7v/+jTZs2fPjhh/To0YOffvqJVatWsWHDhly8VclNU9Ye49c9ETg52DF9YBAN/L2yd4HEOFj+ilkADqBic+g1HbzUSyYiIhllO2Hp27cv0dHRjBs3joiICAICAli+fDmVKlUCICIiIl1NlkGDBhEXF8cXX3zBSy+9hJeXF+3bt+fDDz+0tGnRogXz58/ntdde4/XXX6datWosWLCAZs2a5cItSm5bczCKj1ceAuCt7nVpXq1U9i4QvgMWDTH3o7GzN1emtP6v5qqIiEiWtPmhZMvxc5fp8eVfxCWk0L9pRcb3qnfnJ6elwaYvzM0K05LBowL0ng6Vsh76ExGRwk2bH0qui0tI5unvtltK7r/dvW42Tj4LS4fDsT/M57W7Q/fPVTVVRETuiBIWuSNpaQYvLviHo1GX8fFwYcoTjXF2vMM520dCzCqqV86BYzF4YLy5EkjLZUVE5A4pYZE78tnqI6w6cBZnB3u+HhBE2RJ3UBguJdGsrfL3l+bzsnXhkRlQtlbeBisiIoWOEha5rRX7Ivls9REA3ns4gIZ3siLo/BFY+BRE7jafN30G7h8HTjmsgCsiIkWaEha5pSNn4xi1YBcAg1pUpk/QbZYdG4a52+9vr0ByPBTzNjfNq9kl74MVEZFCSwmLZCkmPplhs7dxJSmVe6t6M7Zr7VufcPUSLHsR9i02n1dpY26a5+GX57GKiEjhpoRFMpWaZjBi/k5ORsdT3qsYXz7WGCeHW0yyDd1sltePCQU7B2j/GrT8P7B3yL+gRUSk0FLCIpn6eOUh1h0+h6uTPV8PCKRUcZfMG6alwvqJsHY8GKngVcmcWFshKH8DFhGRQk0Ji2SwbPcZpq49BsCHvesTUN4z84ZxkbBwCJy6toVCwCPw0ERzTyAREZFcpIRF0tl/JpaXfzRX9jzTpio9GpbPvOHlKJj1EEQfASd36PoxNOiv2ioiIpInlLCIxYUrSTz93TauJqfSukZpXnkgi3op8Rdgdk8zWfGoAAN/gtLV8zVWEREpWpSwCAApqWk8P3cHpy9epaK3G5P7N8LBPpPekoQY+L4XRO2D4j7w5M9Qqlr+BywiIkXKHdZWl8Ju/G8H2XgsGjdnB6YPDMLLzTljo8TLMKcPnNlp1lcZ+JOSFRERyRdKWIRF208TvOEEABMfbUDNciUyNkq+CvP7Q9hmcPGEgUuh7G3qsoiIiOQSJSxF3O7TlxizZA8AL7SvzgMBvhkbpSTBDwPhxJ/gXByeWAS+DfI5UhERKcqUsBRh5+ISeea77SSlpNGhVlle7HhPxkapKbDoKTiy0txp+bEF4N8k/4MVEZEiTQlLEZWUksZzc7YTEZNA1TLuTOrXEPubJ9mmpcLSZ+HAL+DgDP2+h8qtrBOwiIgUaUpYiqhxy/ax9eRFSrg4Mn1gEB6uTukbGAYsGwl7fgB7R+jzLVTvaJVYRURElLAUQfO2hPL936HY2cGn/RpSrUzx9A0MA34fDTtmg5099JoGtR60TrAiIiIoYSlytp+6wBs/7QVgVMd76FDbJ30Dw4DVb8Pmr8znPb6EgN75HKWIiEh6SliKkLOxCQz/fgfJqQZdAsrxfPtMqtP++TFsmGT+3PUTaPhY/gYpIiKSCSUsRURCcirPfLedc3GJ1PQpwcd9GmB3874/GyfDmnfNnzu9B02G5n+gIiIimVDCUgQYhsEbP+1lV9glPFwdmTYwEHeXm3Zl2PoNrHzN/Pm+16DF8/kfqIiISBaUsBQB3/19ih+2ncbeDr54rDGVSrmnb7BrLvz6kvlzqxehzX/zP0gREZFbUMJSyP19PJpxv+wHYHSXWrS5p0z6BnsXwU//MX9uNhw6vAk3DxWJiIhYmRKWQuxo1GX+M2cHKWkG3Rv4Max11fQNDv4Ki58GIw0aPwkPfKBkRUREbJLj7ZtIQbT91AWGfLuNS/HJ1PH14MPe9dNPsj26Cn4cBGkpUL8vPDRJyYqIiNgsJSyF0Mp9kbwwbyeJKWk09PdixqAmFHN2+LfByQ0w/wlITYLa3aHHFLB3yPqCIiIiVqaEpZCZs/kUry/dS5oBHWqVZfJjjXBzvuFjDtsKc/tCylWo0Ql6B4OD/hiIiIht0zdVIWEYBhNDDjP5j6MA9Gviz7s9A3B0uGGaUsQ/8H1vSLoMVdrCo9+Bo7OVIhYREblzSlgKgeTUNMYu2cMP204D8H8dajCyY430c1aiDsB3D0NiDFRsDv3ngZOrlSIWERHJnhytEpoyZQpVqlTB1dWVwMBA1q9fn2XbQYMGYWdnl+FRt25dS5vk5GTGjRtHtWrVcHV1pUGDBvz+++85Ca3IiU9K4enZ2yx1Vsb3qseL99+TPlmJPgaze0B8NPg1gsd+AGf3rC8qIiJiY7KdsCxYsICRI0cyduxYdu7cSevWrenSpQuhoaGZtv/ss8+IiIiwPMLCwvD29qZPnz6WNq+99hpff/01kydPZv/+/QwfPpyHH36YnTt35vzOioDzlxPpP+1v1hw6h6uTPdMGBNG/acX0jS6Fwrfd4fJZ8AmAJxaDq4d1AhYREckhO8MwjOyc0KxZMxo3bszUqVMtx2rXrk3Pnj0ZP378bc9funQpvXr14sSJE1SqVAkAPz8/xo4dy3/+8x9Lu549e1K8eHG+//77O4orNjYWT09PYmJi8PAo/F/Ip6Kv8OSMLZyMjqekmxPBg5rQuGLJ9I3iImFGZ7h4EkrfA4OWQ/EymV5PRETEGu70+ztbc1iSkpLYvn07o0ePTne8U6dObNy48Y6uERwcTMeOHS3JCkBiYiKurunnUxQrVowNGzZkeZ3ExEQSExMtz2NjY+/o/QuD3acvMXjmVqKvJFGhZDG+faop1coUT9/o6kX4rpeZrJSsDAN/UrIiIiIFVraGhM6fP09qaio+Pj7pjvv4+BAZGXnb8yMiIvjtt98YOjT9LsCdO3dm4sSJHDlyhLS0NEJCQvjpp5+IiIjI8lrjx4/H09PT8vD398/OrRRYaw9F0W/a30RfSaKOrweLn22RMVlJioe5/SBqHxT3gQFLwcPPKvGKiIjkhhxNurW7qSKqYRgZjmVm1qxZeHl50bNnz3THP/vsM2rUqEGtWrVwdnbm+eefZ/DgwTg4ZF3MbMyYMcTExFgeYWFhObmVAmXh9tMM/XYb8UmptKpemgXP3EtZj5tW+qQmmxVsw/4GF09zzop3FavEKyIikluylbCULl0aBweHDL0pUVFRGXpdbmYYBjNmzGDAgAE4O6ev/VGmTBmWLl3KlStXOHXqFAcPHqR48eJUqZL1F62LiwseHh7pHoWVYRh8ueYo//3xH1LSDHo29GPGoCaUcHVK3zAtDX56Ho6sAEdXeGwBlAuwTtAiIiK5KFsJi7OzM4GBgYSEhKQ7HhISQosWLW557rp16zh69ChDhgzJso2rqyvly5cnJSWFRYsW0aNHj+yEVyilphm88dM+PlpxCIBn2lZl4qMNcXa86aMzDAh5HXbPBzsH6PMtVGpuhYhFRERyX7YLx40aNYoBAwYQFBRE8+bNmTZtGqGhoQwfPhwwh2rCw8OZPXt2uvOCg4Np1qwZAQEZ/8W/efNmwsPDadiwIeHh4bz11lukpaXxyiuv5PC2CoeE5FT+b/5OVuw7i50dvPFQHQa3zKLXacMk2PSF+XOPL6HmA/kXqIiISB7LdsLSt29foqOjGTduHBEREQQEBLB8+XLLqp+IiIgMNVliYmJYtGgRn332WabXTEhI4LXXXuP48eMUL16cBx98kO+++w4vL6/s31EhcSk+iaHfbmPbqYs4O9gzqW9Dutb3zbzx9m9h9dvmz53eg4b98y9QERGRfJDtOiy2qjDVYQm/dJUnZ2zhaNRlSrg6Mn1gEPdWLZV54wO/wA8DwUiDVi9Cx7fyNVYREZG7kSd1WCTvHYiIZdDMLZyNTaSchyvfPtWUmuVKZN74xHpYOMRMVhoNgA5v5m+wIiIi+UQJiw3ZeOw8z8zeTlxiCvf4FGfW4Kb4eRXLvPGZXTCvP6QmQq2H4KFP4Q6WlouIiBRESlhsxC//nOGlH/4hKTWNppW9mT4wCE83p8wbRx+D73tDUhxUbg29g8FBH6WIiBRe+pazAcEbTvDOsv0AdAkox6S+DXF1yqJoXmwEfNcT4s9DufrQby44uWbeVkREpJBQwmJlH604yJdrjgHwZPNKvNGtLg72WQztXL0I3/cyd2D2rgpPLNLOyyIiUiQoYbGisAvxlmTl1QdqMbxt1ay3OLDsD7QfipeDAUugeNl8jFZERMR6lLBYUcj+swDcW9WbZ9tVy7rhjfsDuXrCgMXmDswiIiJFRI42P5TcsWKfuSdTpzrlsm508/5A/ReAT918ilBERMQ2KGGxkgtXkth68gIAnepmsXGkYcDK1/7dH+jR2dofSEREiiQlLFay6sBZ0gyo6+dBhZJumTfaMAn+/tL8uecUuKdz/gUoIiJiQ5SwWMnKfeb8lSyHg27cH6jz+9CgXz5FJiIiYnuUsFhBfFIK64+cA6BzQCbDQft/hmUjzZ9bvQjN/5N/wYmIiNggJSxW8OfhcySmpFHR242aPjftE3TiT1h0bX+gxgO1P5CIiAhKWKzi+nBQ57o+6euunNkF8x6D1CRzf6Cuk7Q/kIiICEpY8l1yahqrDlybv1L3hvkr2h9IREQkS0pY8tmWExeITUihlLszjSuWNA9qfyAREZFbUsKSz64Xi7u/jo+5Z5D2BxIREbktJSz5yDCMf5cz1/UxC8PNf0L7A4mIiNyGEpZ8tCc8hsjYBNydHWhRrTRE7oZTG8yS+9ofSEREJEtKWPLR9eGgdjXL4urkAId+N1+o1kH7A4mIiNyCEpZ8lG44CODwtYRFJfdFRERuSQlLPjl+7jJHoi7j5GDHfbXKQlwknNlhvqiERURE5JaUsOSTlfvN3pV7q5bCw9UJDq8wX/BrDCWy2E9IREREACUs+Wbltfkrna8Xi7uesNzzgJUiEhERKTiUsOSDqNgEdoReAsz6KyQnwPE15os1lbCIiIjcjhKWfBByrRR/Q38vfDxc4eR6SI6HEn5mZVsRERG5JSUs+WCFZbPDa8NBh34z/3tPZ21uKCIicgeUsOSx2IRkNh07D9xQ3fb6/JWaXawYmYiISMGhhCWPrTkYRXKqQfWyxalWpjic3Quxp8GxGFRpY+3wRERECgQlLHns+nLmTnWuFYu7Xt22ajtwKmadoERERAqYHCUsU6ZMoUqVKri6uhIYGMj69euzbDto0CDs7OwyPOrWTV+K/tNPP6VmzZoUK1YMf39/XnzxRRISEnISns1ITEll7cEoADpZljOruq2IiEh2ZTthWbBgASNHjmTs2LHs3LmT1q1b06VLF0JDQzNt/9lnnxEREWF5hIWF4e3tTZ8+fSxt5syZw+jRo3nzzTc5cOAAwcHBLFiwgDFjxuT8zmzAxqPRXElKpZyHK/XLe8LlKAjfbr6o+isiIiJ3LNsJy8SJExkyZAhDhw6ldu3afPrpp/j7+zN16tRM23t6elKuXDnLY9u2bVy8eJHBgwdb2mzatImWLVvy2GOPUblyZTp16kT//v3Ztm1bzu/MBqzcbxaLu7+OD/b2dtcm2xrg2xA8fK0am4iISEGSrYQlKSmJ7du306lTp3THO3XqxMaNG+/oGsHBwXTs2JFKlSpZjrVq1Yrt27ezZcsWAI4fP87y5cvp2rVrltdJTEwkNjY23cOWpKYZhOy/aTmzZThIvSsiIiLZ4ZidxufPnyc1NRUfH590x318fIiMjLzt+REREfz222/MnTs33fF+/fpx7tw5WrVqhWEYpKSk8OyzzzJ69OgsrzV+/Hjefvvt7ISfr3aGXuT85SRKuDrSrKq3Wd32mKrbioiI5ESOJt3a3VTszDCMDMcyM2vWLLy8vOjZs2e642vXruW9995jypQp7Nixg8WLF7Ns2TLeeeedLK81ZswYYmJiLI+wsLCc3Eqeub46qEOtsjg52MOpDZB8BYqXg3INrBydiIhIwZKtHpbSpUvj4OCQoTclKioqQ6/LzQzDYMaMGQwYMABnZ+d0r73++usMGDCAoUOHAlCvXj2uXLnC008/zdixY7G3z5hXubi44OLikp3w841hGKy4ebPDQzesDsrkfkRERCRr2frmdHZ2JjAwkJCQkHTHQ0JCaNGixS3PXbduHUePHmXIkCEZXouPj8+QlDg4OGAYBoZhZCdEm3D47GVORcfj7GhPm3vKXKtuey1hUXVbERGRbMtWDwvAqFGjGDBgAEFBQTRv3pxp06YRGhrK8OHDAXOoJjw8nNmzZ6c7Lzg4mGbNmhEQEJDhmt26dWPixIk0atSIZs2acfToUV5//XW6d++Og4NDDm/Neq73rrSpURp3F0c4uw9iwsDRFaq0tXJ0IiIiBU+2E5a+ffsSHR3NuHHjiIiIICAggOXLl1tW/URERGSoyRITE8OiRYv47LPPMr3ma6+9hp2dHa+99hrh4eGUKVOGbt268d577+Xglqzv+nLmTnVu2uywSltwdrNSVCIiIgWXnVEQx1wyERsbi6enJzExMXh4eFgtjtMX42n14Rrs7WDr2I6UKu4C39wPp7dA14nQJOOQmIiISFF1p9/fmv2Zy67XXgmq7G0mK5fPwemt5ouqvyIiIpIjSlhy2cp9N212eDQEMKBcffAsb73ARERECjAlLLno4pUktpy8ANy4nPna/BX1roiIiOSYEpZctPpgFKlpBrV9PfD3doOURDj2h/miqtuKiIjkmBKWXHR9ObNlOOjUX5B0GYr7gG8jK0YmIiJSsClhySVXk1JZf+QckEl12xqdVN1WRETkLuhbNJf8eeQcCclpVChZjNq+JVTdVkREJBcpYcklN+4dZGdnB+cOwqVT4OACVdtZNzgREZECTglLLkhJTWP1gSjghvkrluq2bcDZ3UqRiYiIFA5KWHLBlhMXiLmajLe7M0GVvc2Dh1eY/72ns/UCExERKSSUsOSCldeq23asXRYHezu4Em2W4gfVXxEREckFSljukmEYrNx302aHR0PASAOfeuDlb8XoRERECgclLHdpb3gsZ2IScHN2oFWN0uZBS3VbDQeJiIjkBiUsd2nlfrN3pe09ZXB1coCUJDi62nxRy5lFRERyhRKWu2Spblv32uqg0I2QFAfuZcCvsRUjExERKTyUsNyFE+evcPjsZRzt7Whf8/py5uvVbTuruq2IiEgu0TfqXbg+2fbeqqXwdHO6Vt322vwVbXYoIiKSa5Sw3IXry5k7Xx8OOn8YLp4EB2eoep/1AhMRESlklLDkUFRcAjtCLwLQ8ebqtpVbg0txK0UmIiJS+ChhyaFV+6MwDGhQwRNfz2LmQUt1Ww0HiYiI5CYlLDl0fTlzp7rXisXFX4Cwv82fNX9FREQkVylhyYG4hGQ2Ho0Gbpi/cnSVWd22bF3wqmjF6ERERAofJSw5sPbQOZJS06haxp3qZUuYB1XdVkREJM8oYcmB66uDLHsHpSaruq2IiEgeUsKSTYkpqaw5GAXcWN12EyTGgFspKB9oxehEREQKJyUs2bTpWDSXE1MoW8KFhhW8zIPpqts6WC02ERGRwkoJSzat2GcOB91fxwd7ezvz4OFrCYtWB4mIiOQJJSzZkJZmEGKpbntt/sr5I3DhGNg7qbqtiIhIHlHCkg07wy5x/nIiJVwcubdqKfPg9d6Vyq3A1cN6wYmIiBRiSliy4fpmh/fVKouz47X/ddfnr6i6rYiISJ7JUcIyZcoUqlSpgqurK4GBgaxfvz7LtoMGDcLOzi7Do27dupY27dq1y7RN165dcxJenjAMgxXXEhbLcNDVi+YKIdD8FRERkTyU7YRlwYIFjBw5krFjx7Jz505at25Nly5dCA0NzbT9Z599RkREhOURFhaGt7c3ffr0sbRZvHhxujZ79+7FwcEhXRtrOxJ1mZPR8Tg72tO2Zhnz4NHVYKRCmdpQsrJV4xMRESnMsp2wTJw4kSFDhjB06FBq167Np59+ir+/P1OnTs20vaenJ+XKlbM8tm3bxsWLFxk8eLCljbe3d7o2ISEhuLm52VTCcn04qFX10hR3cTQPqrqtiIhIvshWwpKUlMT27dvp1KlTuuOdOnVi48aNd3SN4OBgOnbsSKVKlW7Zpl+/fri7u2fZJjExkdjY2HSPvHR9OXOnOteKxaWmwNEQ82dVtxUREclT2UpYzp8/T2pqKj4+PumO+/j4EBkZedvzIyIi+O233xg6dGiWbbZs2cLevXtv2QZg/PjxeHp6Wh7+/v53dhM5cObSVfaEx2BnBx1qX7v3sL8hIQaKeUOFJnn23iIiIpLDSbd2dnbpnhuGkeFYZmbNmoWXlxc9e/bMsk1wcDABAQE0bdr0ltcaM2YMMTExlkdYWNgdxZ4T12uvBFUqSZkSLubB68NBNTqpuq2IiEgec8xO49KlS+Pg4JChNyUqKipDr8vNDMNgxowZDBgwAGdn50zbxMfHM3/+fMaNG3fbWFxcXHBxcbnz4O/C9dVBls0OAQ6vMP+r1UEiIiJ5Lls9LM7OzgQGBhISEpLueEhICC1atLjluevWrePo0aMMGTIkyzY//PADiYmJPPHEE9kJK09dik9i84kLwA2bHUYfg+gjYO8I1dpbMToREZGiIVs9LACjRo1iwIABBAUF0bx5c6ZNm0ZoaCjDhw8HzKGa8PBwZs+ene684OBgmjVrRkBAQJbXDg4OpmfPnpQqVSq7YeWZ1QeiSE0zqFWuBJVKXZsEfL26baWW4OppveBERESKiGwnLH379iU6Oppx48YRERFBQEAAy5cvt6z6iYiIyFCTJSYmhkWLFvHZZ59led3Dhw+zYcMGVq5cmd2Q8tTK/deHg24Y8rIsZ9ZwkIiISH6wMwzDsHYQuSE2NhZPT09iYmLw8MidPX0Mw+DhKRvZFXaJZS+0IqC8J1y9BB9Vg7QUGLETvKvmynuJiIgURXf6/Z3tHpaixM7OjqX/aUlodDz+3sXMg8dWm8lK6ZpKVkRERPKJEpY7ULGU279PLJsdqrqtiIhIftFuzdmh6rYiIiJWoYQlO05vMXdodvWCCrcubCciIiK5RwlLdtxY3dZBo2kiIiL5RQlLdqi6rYiIiFUoYblTF47D+UPXqtt2sHY0IiIiRYoSljt1vXelYnMo5mXVUERERIoaJSx3StVtRURErEYJy51IiIVTf5k/azmziIhIvlPCcieuV7ctVQNKVbN2NCIiIkWOEpY7oeq2IiIiVqWE5XbSUuHItR2kNRwkIiJiFUpYbuf0Vrh6AVw9wb+ZtaMREREpkpSw3M7ha8NB1e8HByfrxiIiIlJEKWG5nevzVzQcJCIiYjXaEOdWDAPavWomLdXaWzsaERGRIksJy63Y2UHdh82HiIiIWI2GhERERMTmKWERERERm6eERURERGyeEhYRERGxeUpYRERExOYpYRERERGbp4RFREREbJ4SFhEREbF5SlhERETE5ilhEREREZunhEVERERsnhIWERERsXlKWERERMTmFZrdmg3DACA2NtbKkYiIiMiduv69ff17PCuFJmGJi4sDwN/f38qRiIiISHbFxcXh6emZ5et2xu1SmgIiLS2NM2fOUKJECezs7KwdTp6JjY3F39+fsLAwPDw8rB1OnipK9wpF6351r4VXUbpf3WvuMAyDuLg4/Pz8sLfPeqZKoelhsbe3p0KFCtYOI994eHgU+l+Q64rSvULRul/da+FVlO5X93r3btWzcp0m3YqIiIjNU8IiIiIiNk8JSwHj4uLCm2++iYuLi7VDyXNF6V6haN2v7rXwKkr3q3vNX4Vm0q2IiIgUXuphEREREZunhEVERERsnhIWERERsXlKWERERMTmKWGxIePHj6dJkyaUKFGCsmXL0rNnTw4dOnTLc9auXYudnV2Gx8GDB/Mp6px56623MsRcrly5W56zbt06AgMDcXV1pWrVqnz11Vf5FO3dq1y5cqaf03/+859M2xekz/XPP/+kW7du+Pn5YWdnx9KlS9O9bhgGb731Fn5+fhQrVox27dqxb9++21530aJF1KlTBxcXF+rUqcOSJUvy6A7u3K3uNTk5mVdffZV69erh7u6On58fAwcO5MyZM7e85qxZszL9rBMSEvL4bm7vdp/toEGDMsR977333va6Be2zBTL9jOzs7Pjoo4+yvKatfrZ38l1ji7+3SlhsyLp16/jPf/7D33//TUhICCkpKXTq1IkrV67c9txDhw4RERFhedSoUSMfIr47devWTRfznj17smx74sQJHnzwQVq3bs3OnTv53//+x4gRI1i0aFE+RpxzW7duTXevISEhAPTp0+eW5xWEz/XKlSs0aNCAL774ItPXJ0yYwMSJE/niiy/YunUr5cqV4/7777fs/5WZTZs20bdvXwYMGMA///zDgAEDePTRR9m8eXNe3cYdudW9xsfHs2PHDl5//XV27NjB4sWLOXz4MN27d7/tdT08PNJ9zhEREbi6uubFLWTL7T5bgAceeCBd3MuXL7/lNQviZwtk+HxmzJiBnZ0dvXv3vuV1bfGzvZPvGpv8vTXEZkVFRRmAsW7duizbrFmzxgCMixcv5l9gueDNN980GjRocMftX3nlFaNWrVrpjj3zzDPGvffem8uR5Y//+7//M6pVq2akpaVl+npB/VwBY8mSJZbnaWlpRrly5YwPPvjAciwhIcHw9PQ0vvrqqyyv8+ijjxoPPPBAumOdO3c2+vXrl+sx59TN95qZLVu2GIBx6tSpLNvMnDnT8PT0zN3g8kBm9/vkk08aPXr0yNZ1Cstn26NHD6N9+/a3bFNQPtubv2ts9fdWPSw2LCYmBgBvb+/btm3UqBG+vr506NCBNWvW5HVoueLIkSP4+flRpUoV+vXrx/Hjx7Nsu2nTJjp16pTuWOfOndm2bRvJycl5HWquSkpK4vvvv+epp5667UadBfFzvdGJEyeIjIxM99m5uLjQtm1bNm7cmOV5WX3etzrHFsXExGBnZ4eXl9ct212+fJlKlSpRoUIFHnroIXbu3Jk/AeaCtWvXUrZsWe655x6GDRtGVFTULdsXhs/27Nmz/PrrrwwZMuS2bQvCZ3vzd42t/t4qYbFRhmEwatQoWrVqRUBAQJbtfH19mTZtGosWLWLx4sXUrFmTDh068Oeff+ZjtNnXrFkzZs+ezYoVK5g+fTqRkZG0aNGC6OjoTNtHRkbi4+OT7piPjw8pKSmcP38+P0LONUuXLuXSpUsMGjQoyzYF9XO9WWRkJECmn93117I6L7vn2JqEhARGjx7NY489dsvN4mrVqsWsWbP4+eefmTdvHq6urrRs2ZIjR47kY7Q506VLF+bMmcMff/zBJ598wtatW2nfvj2JiYlZnlMYPttvv/2WEiVK0KtXr1u2KwifbWbfNbb6e1todmsubJ5//nl2797Nhg0bbtmuZs2a1KxZ0/K8efPmhIWF8fHHH9OmTZu8DjPHunTpYvm5Xr16NG/enGrVqvHtt98yatSoTM+5uTfCuFak+Xa9FLYmODiYLl264Ofnl2Wbgvq5ZiWzz+52n1tOzrEVycnJ9OvXj7S0NKZMmXLLtvfee2+6iaotW7akcePGTJ48mc8//zyvQ70rffv2tfwcEBBAUFAQlSpV4tdff73ll3lB/mwBZsyYweOPP37buSgF4bO91XeNrf3eqofFBr3wwgv8/PPPrFmzhgoVKmT7/HvvvdemMvg74e7uTr169bKMu1y5chmy9KioKBwdHSlVqlR+hJgrTp06xapVqxg6dGi2zy2In+v1lV+ZfXY3/0vs5vOye46tSE5O5tFHH+XEiROEhITcsnclM/b29jRp0qTAfdZg9gxWqlTplrEX5M8WYP369Rw6dChHv8O29tlm9V1jq7+3SlhsiGEYPP/88yxevJg//viDKlWq5Og6O3fuxNfXN5ejy1uJiYkcOHAgy7ibN29uWVlz3cqVKwkKCsLJySk/QswVM2fOpGzZsnTt2jXb5xbEz7VKlSqUK1cu3WeXlJTEunXraNGiRZbnZfV53+ocW3A9WTly5AirVq3KUTJtGAa7du0qcJ81QHR0NGFhYbeMvaB+ttcFBwcTGBhIgwYNsn2urXy2t/uusdnf21yZuiu54tlnnzU8PT2NtWvXGhEREZZHfHy8pc3o0aONAQMGWJ5PmjTJWLJkiXH48GFj7969xujRow3AWLRokTVu4Y699NJLxtq1a43jx48bf//9t/HQQw8ZJUqUME6ePGkYRsb7PH78uOHm5ma8+OKLxv79+43g4GDDycnJWLhwobVuIdtSU1ONihUrGq+++mqG1wry5xoXF2fs3LnT2LlzpwEYEydONHbu3GlZGfPBBx8Ynp6exuLFi409e/YY/fv3N3x9fY3Y2FjLNQYMGGCMHj3a8vyvv/4yHBwcjA8++MA4cOCA8cEHHxiOjo7G33//ne/3d6Nb3WtycrLRvXt3o0KFCsauXbvS/Q4nJiZarnHzvb711lvG77//bhw7dszYuXOnMXjwYMPR0dHYvHmzNW4xnVvdb1xcnPHSSy8ZGzduNE6cOGGsWbPGaN68uVG+fPlC99leFxMTY7i5uRlTp07N9BoF5bO9k+8aW/y9VcJiQ4BMHzNnzrS0efLJJ422bdtann/44YdGtWrVDFdXV6NkyZJGq1atjF9//TX/g8+mvn37Gr6+voaTk5Ph5+dn9OrVy9i3b5/l9Zvv0zAMY+3atUajRo0MZ2dno3Llyln+pWGrVqxYYQDGoUOHMrxWkD/X60uwb348+eSThmGYSyTffPNNo1y5coaLi4vRpk0bY8+ePemu0bZtW0v763788UejZs2ahpOTk1GrVi2bSNZuda8nTpzI8nd4zZo1lmvcfK8jR440KlasaDg7OxtlypQxOnXqZGzcuDH/by4Tt7rf+Ph4o1OnTkaZMmUMJycno2LFisaTTz5phIaGprtGYfhsr/v666+NYsWKGZcuXcr0GgXls72T7xpb/L21uxa8iIiIiM3SHBYRERGxeUpYRERExOYpYRERERGbp4RFREREbJ4SFhEREbF5SlhERETE5ilhEREREZunhEVERERsnhIWERERsXlKWERERMTmKWERERERm6eERURERGze/wNhq5C8ZQGoHAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = np.linspace(1,20, 20)\n",
    "plt.plot(epochs, train_error, label = 'Train Accuracy')\n",
    "plt.plot(epochs, test_error, label = 'Test Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ee6086a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's produce the output on the test_set \n",
    "torch_test = MusicDataset(test_set, is_test=True, transform=preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fd4cb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now let's train an XGboost and/or Random Forest Model\n",
    "\n",
    "dataset = MusicDataset(training_set, is_test= False, transform=preprocessing)\n",
    "X_np = dataset.X.numpy()\n",
    "y_np = dataset.y.numpy()\n",
    "\n",
    "torch_test = MusicDataset(test_set, is_test=True, transform=preprocessing)\n",
    "\n",
    "X_test_np = torch_test.X.numpy()\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_np, y_np, test_size= 0.15, random_state=37)\n",
    "XGboost = XGBClassifier(objective='binary:logistic', n_estimators = 100, max_depth = 6)\n",
    "XGboost.fit(X_np, y_np)\n",
    "y_pred = XGboost.predict_proba(X_test_np)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8acb40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfc_clf = RandomForestClassifier(criterion='gini', n_estimators=100, max_depth=150)\n",
    "# rfc_clf.fit(X_train, y_train)\n",
    "# y_pred = rfc_clf.predict(X_test)\n",
    "# acc = accuracy_score(y_pred, y_test)\n",
    "# print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06274574",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "9acd5558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide up data\n",
    "dataset = MusicDataset(training_set, is_test=False, transform=preprocessing)\n",
    "train_dataset, valid_dataset = split_data(dataset)\n",
    "X = dataset.X.squeeze()\n",
    "y = dataset.y.squeeze()\n",
    "X_train = train_dataset.dataset.X[train_dataset.indices].squeeze()\n",
    "y_train = train_dataset.dataset.y[train_dataset.indices].squeeze()\n",
    "X_valid = valid_dataset.dataset.X[valid_dataset.indices].squeeze()\n",
    "y_valid = valid_dataset.dataset.y[valid_dataset.indices].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "e5a089cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get features list\n",
    "features = dataset.__getlabels__()[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "4fbfd42a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>feature_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>instrumentalness</td>\n",
       "      <td>0.323686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>year</td>\n",
       "      <td>0.102268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>loudness</td>\n",
       "      <td>0.065940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>acousticness</td>\n",
       "      <td>0.064749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>energy</td>\n",
       "      <td>0.049612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>danceability</td>\n",
       "      <td>0.049183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>duration_ms</td>\n",
       "      <td>0.046299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>valence</td>\n",
       "      <td>0.044653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>day</td>\n",
       "      <td>0.043445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>month</td>\n",
       "      <td>0.042253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tempo</td>\n",
       "      <td>0.035905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>speechiness</td>\n",
       "      <td>0.032724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>liveness</td>\n",
       "      <td>0.032110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>time_signature</td>\n",
       "      <td>0.024400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>key</td>\n",
       "      <td>0.021938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mode</td>\n",
       "      <td>0.020835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             feature  feature_importance\n",
       "6   instrumentalness            0.323686\n",
       "13              year            0.102268\n",
       "10          loudness            0.065940\n",
       "11      acousticness            0.064749\n",
       "4             energy            0.049612\n",
       "2       danceability            0.049183\n",
       "3        duration_ms            0.046299\n",
       "7            valence            0.044653\n",
       "15               day            0.043445\n",
       "14             month            0.042253\n",
       "9              tempo            0.035905\n",
       "1        speechiness            0.032724\n",
       "12          liveness            0.032110\n",
       "0     time_signature            0.024400\n",
       "8                key            0.021938\n",
       "5               mode            0.020835"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train XGBoost on model and identify most important features\n",
    "model = XGBClassifier(objective='binary:logistic', n_estimators = 100, max_depth = 3)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Define table with features and feature importances\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'feature': features,\n",
    "        'feature_importance': model.feature_importances_\n",
    "    }\n",
    ")\n",
    "df.sort_values(by='feature_importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "9c58ccf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove irrelevant features\n",
    "bad_features = list(df[df['feature_importance'] < 0.02]['feature']) # 0.04 best\n",
    "dataset = MusicDataset(training_set, is_test= False, transform=preprocessing,\n",
    "                       to_remove=bad_features)\n",
    "train_dataset, valid_dataset = split_data(dataset)\n",
    "torch_test = MusicDataset(test_set, is_test=True, transform=preprocessing,\n",
    "                          to_remove=bad_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "60801ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide up data\n",
    "X = dataset.X.squeeze()\n",
    "y = dataset.y.squeeze()\n",
    "X_train = train_dataset.dataset.X[train_dataset.indices].squeeze()\n",
    "y_train = train_dataset.dataset.y[train_dataset.indices].squeeze()\n",
    "X_valid = valid_dataset.dataset.X[valid_dataset.indices].squeeze()\n",
    "y_valid = valid_dataset.dataset.y[valid_dataset.indices].squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332f81cd",
   "metadata": {},
   "source": [
    "# Ensemble selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "c2a55a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_selection(models, valid_pred, y_valid, max_size, resampling=False):\n",
    "    \"\"\"\n",
    "    Performs ensemble selection given a list of models trained on test to\n",
    "    maximize AUC\n",
    "\n",
    "    Args:\n",
    "        models: array of models trained\n",
    "        valid_pred: predictions for validation set\n",
    "        y_valid: true values for validation set\n",
    "    \n",
    "    Returns:\n",
    "        Ensemble of models that maximizes AUC on the validation set\n",
    "    \"\"\"\n",
    "    ensemble = []\n",
    "    remaining = list(models)\n",
    "\n",
    "    best_auc = 0\n",
    "    while len(ensemble) < max_size:\n",
    "        best_model = None\n",
    "\n",
    "        for m in remaining:\n",
    "            candidate = ensemble + [m]\n",
    "            preds = np.mean([valid_pred[x] for x in candidate], axis=0)\n",
    "            auc = roc_auc_score(y_valid, preds)\n",
    "\n",
    "            if auc >= best_auc:\n",
    "                best_auc = auc\n",
    "                best_model = m\n",
    "\n",
    "        if best_model is None:\n",
    "            break\n",
    "\n",
    "        ensemble.append(best_model)\n",
    "        if not resampling:\n",
    "            remaining.remove(best_model)\n",
    "        print(best_auc)\n",
    "\n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "adadc050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of parameters\n",
    "nn_params_list = [\n",
    "    dict(hidden_units=64,  dropout=0.5,  lr=1e-3),\n",
    "    dict(hidden_units=128, dropout=0.3,  lr=5e-4),\n",
    "    dict(hidden_units=256, dropout=0.2,  lr=3e-4),\n",
    "    dict(hidden_units=32, dropout=0.1,  lr=1e-4),\n",
    "]\n",
    "\n",
    "xgboost_params_list = [ \n",
    "    dict(max_depth=6, learning_rate=0.1, subsample=0.5, colsample_bytree=0.6), \n",
    "    dict(max_depth=5, learning_rate=0.05, subsample=0.4, colsample_bytree=0.5), \n",
    "    dict(max_depth=4, learning_rate=0.03, subsample=0.6, colsample_bytree=0.4),\n",
    "    dict(max_depth=3, learning_rate=0.02, subsample=0.4, colsample_bytree=0.3),\n",
    "]\n",
    "\n",
    "random_forest_params_list = [\n",
    "    dict(max_depth=8, max_features=0.5),\n",
    "    dict(max_depth=12, max_features=\"sqrt\"),\n",
    "    dict(max_depth=None, max_features=0.3),\n",
    "]\n",
    "\n",
    "light_gbm_params_list = [\n",
    "    dict(num_leaves=31, learning_rate=0.05, colsample_bytree=0.4),\n",
    "    dict(num_leaves=63, learning_rate=0.03, colsample_bytree=0.3)\n",
    "]\n",
    "\n",
    "logistic_params_list = [\n",
    "    dict(C=10**n) for n in range(-2, 3)\n",
    "]\n",
    "\n",
    "# Training models\n",
    "def train_nn(hidden_units, dropout, lr):\n",
    "    # Define neural network\n",
    "    neuralnet = nn.Sequential(\n",
    "        nn.Linear(num_features, hidden_units),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(dropout),\n",
    "\n",
    "        nn.Linear(hidden_units, hidden_units // 2),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(dropout),\n",
    "\n",
    "        nn.Linear(hidden_units // 2, 1),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    optimizer = torch.optim.NAdam(neuralnet.parameters(), lr=lr)\n",
    "    loss_fn = nn.BCELoss()\n",
    "\n",
    "    # Training model\n",
    "    neuralnet.train()\n",
    "    for _ in range(20):\n",
    "        for _, (data, target) in enumerate(training_data_loader):\n",
    "            # Erase accumulated gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            output = neuralnet(data)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = loss_fn(output.squeeze(), target.float())\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            \n",
    "            # Weight update\n",
    "            optimizer.step()\n",
    "\n",
    "    # turn off training\n",
    "    neuralnet.eval()\n",
    "    return neuralnet\n",
    "\n",
    "def train_xgboost(max_depth, learning_rate, subsample, colsample_bytree):\n",
    "    model = XGBClassifier(objective='binary:logistic', \n",
    "                          n_estimators = 800, max_depth = max_depth,\n",
    "                          learning_rate = learning_rate, subsample = subsample,\n",
    "                          colsample_bytree = colsample_bytree, eval_metric='auc')\n",
    "    model.fit(X_train.numpy(), y_train.numpy())\n",
    "    return model\n",
    "\n",
    "def train_random_forest(max_depth, max_features):\n",
    "    model = RandomForestClassifier(criterion='entropy', n_estimators=100,\n",
    "                          max_depth=max_depth, max_features=max_features)\n",
    "    model.fit(X_train.numpy(), y_train.numpy())\n",
    "    return model\n",
    "\n",
    "def train_light_gbm(num_leaves, learning_rate, colsample_bytree):\n",
    "    model = LGBMClassifier(num_leaves=num_leaves, learning_rate=learning_rate,\n",
    "                           colsample_bytree=colsample_bytree, verbosity=-1)\n",
    "    model.fit(X_train.numpy(), y_train.numpy())\n",
    "    return model\n",
    "\n",
    "def train_logistic(C):\n",
    "    model = LogisticRegression(C=C, penalty='l2')\n",
    "    model.fit(X_train.numpy(), y_train.numpy())\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "b89d921a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train all nn models and evaluate on validation\n",
    "# nn_models = []\n",
    "# for param in nn_params_list:\n",
    "#     nn_models += [train_nn(param['hidden_units'], param['dropout'], param['lr'])]\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     nn_valid_pred = { \n",
    "#         model: model(X_valid).numpy().flatten()\n",
    "#         for model in nn_models \n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "1fb966db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost and evaluate on validation\n",
    "xgboost_models = []\n",
    "for param in xgboost_params_list:\n",
    "    xgboost_models += [train_xgboost(param['max_depth'], \n",
    "                                     param['learning_rate'],\n",
    "                                     param['subsample'],\n",
    "                                     param['colsample_bytree'])]\n",
    "\n",
    "xgboost_valid_pred = { \n",
    "    model: model.predict_proba(X_valid)[:, 1]\n",
    "    for model in xgboost_models \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "504b58e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest and evaluate on validation\n",
    "random_forest_models = []\n",
    "for param in random_forest_params_list:\n",
    "    random_forest_models += [train_random_forest(param['max_depth'], \n",
    "                                                 param['max_features'])]\n",
    "\n",
    "random_forest_valid_pred = { \n",
    "    model: model.predict_proba(X_valid)[:, 1]\n",
    "    for model in random_forest_models \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "9826841e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# LGBM complains when there are no labels\n",
    "warnings.filterwarnings(\n",
    "    action='ignore', \n",
    "    category=UserWarning, \n",
    "    module='sklearn.utils.validation'\n",
    ")\n",
    "\n",
    "# Train Random Forest and evaluate on validation\n",
    "lgbm_models = []\n",
    "for param in light_gbm_params_list:\n",
    "    lgbm_models += [train_light_gbm(param['num_leaves'], \n",
    "                                    param['learning_rate'],\n",
    "                                    param['colsample_bytree'])]\n",
    "\n",
    "lgbm_valid_pred = { \n",
    "    model: model.predict_proba(X_valid)[:, 1]\n",
    "    for model in lgbm_models \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "852377d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression and evaluate on validation\n",
    "logistic_models = []\n",
    "for param in logistic_params_list:\n",
    "    logistic_models += [train_logistic(param['C'])]\n",
    "\n",
    "logistic_valid_pred = { \n",
    "    model: model.predict_proba(X_valid)[:, 1]\n",
    "    for model in logistic_models \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "ef2922e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble draws from 12 models\n"
     ]
    }
   ],
   "source": [
    "# Combine everything\n",
    "models = xgboost_models + random_forest_models + logistic_models\n",
    "valid_pred = xgboost_valid_pred | random_forest_valid_pred | logistic_valid_pred\n",
    "print(f'Ensemble draws from {len(models)} models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "1359a1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8553039403241832\n",
      "0.8578176209755157\n",
      "0.8578250359626878\n",
      "0.8588038142694012\n"
     ]
    }
   ],
   "source": [
    "# Run ensemble method\n",
    "ensemble = ensemble_selection(models, valid_pred, y_valid.numpy(), max_size=len(models) * 2, resampling=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "81459b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n"
     ]
    }
   ],
   "source": [
    "# Check types of models contained\n",
    "for model in ensemble:\n",
    "    print(type(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdd4463",
   "metadata": {},
   "source": [
    "# Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "a4cecfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(n_splits, ensemble):\n",
    "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, val_idx in cv.split(X, y):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        preds = []\n",
    "\n",
    "        for model in ensemble:\n",
    "            model.fit(X_train, y_train)\n",
    "            preds.append(model.predict_proba(X_val)[:, 1])\n",
    "\n",
    "        ensemble_pred = np.mean(preds, axis=0)\n",
    "        scores.append(roc_auc_score(y_val, ensemble_pred))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "b2d5ac14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean AUC is 0.8431956303326997 +/- 0.006684471113322926\n"
     ]
    }
   ],
   "source": [
    "scores = cross_validation(n_splits=10, ensemble=ensemble)\n",
    "print(f'The mean AUC is {np.mean(scores)} +/- {np.std(scores)/np.sqrt(10)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9ce737",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "4bc36f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stack\n",
    "estimators = [\n",
    "    (f\"xgb{i}\", clone(model)) for i, model in enumerate(xgboost_models + lgbm_models + random_forest_models + logistic_models)\n",
    "]\n",
    "for i, (j, model) in enumerate(estimators):\n",
    "    model.set_params(random_state=i)\n",
    "stack = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=clone(random_forest_models[0]),\n",
    "    stack_method=\"predict_proba\",\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "0b452206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(\n",
    "    stack,\n",
    "    X,\n",
    "    y,\n",
    "    cv=outer_cv,\n",
    "    scoring=\"roc_auc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "0656e5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean AUC is 0.8382454431272034 +/- 0.007615493967840164\n"
     ]
    }
   ],
   "source": [
    "print(f'The mean AUC is {np.mean(scores)} +/- {np.std(scores)/np.sqrt(5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "74511a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.84144310e-01, 2.64782179e-01, 6.55449790e-01, 7.17308130e-01,\n",
       "       2.37762195e-01, 5.09988851e-02, 3.29638626e-01, 2.71852998e-01,\n",
       "       9.79597089e-01, 4.23331765e-01, 2.67500157e-01, 3.33263073e-01,\n",
       "       3.86586679e-01, 2.24389319e-01, 4.60708964e-01, 6.45436943e-01,\n",
       "       2.43024512e-01, 4.81145571e-03, 8.53362703e-03, 2.44703066e-01,\n",
       "       2.29714269e-01, 1.47718050e-02, 2.40894747e-03, 1.85345577e-03,\n",
       "       9.03066517e-02, 1.42172635e-01, 4.11802846e-01, 5.03120255e-01,\n",
       "       1.25562830e-02, 1.37947749e-01, 2.38115909e-01, 3.91118306e-01,\n",
       "       1.15224602e-02, 1.56725744e-02, 2.09481671e-01, 1.62496415e-01,\n",
       "       8.40542218e-02, 4.56320478e-02, 3.13063643e-01, 2.33265389e-01,\n",
       "       3.49001141e-01, 1.17674710e-02, 5.70497185e-01, 3.66027988e-01,\n",
       "       2.43385202e-01, 6.80491274e-01, 9.71666667e-01, 6.25077360e-04,\n",
       "       3.08923843e-01, 1.31205582e-01, 7.54063725e-01, 4.65049041e-01,\n",
       "       2.05538716e-01, 8.45575838e-01, 1.09174788e-03, 3.67564427e-03,\n",
       "       3.63702237e-01, 4.18987438e-01, 9.24011271e-02, 4.89546451e-01,\n",
       "       2.13543746e-01, 4.89940015e-01, 1.67593291e-03, 2.67790827e-01,\n",
       "       1.76133837e-03, 4.23898759e-01, 6.88837069e-01, 5.19345236e-02,\n",
       "       4.37061375e-03, 3.06804560e-01, 5.62672205e-04, 1.97701190e-01,\n",
       "       2.61984271e-01, 1.35484772e-01, 6.51703849e-01, 4.13222603e-01,\n",
       "       4.75711460e-02, 5.10806061e-02, 4.99284707e-01, 4.82602614e-02,\n",
       "       2.38656242e-01, 4.34941396e-01, 2.94527375e-01, 3.54500375e-01,\n",
       "       1.24329464e-01, 4.09270782e-01, 3.03070024e-01, 3.23899789e-02,\n",
       "       1.25977840e-01, 2.74040669e-01, 1.34750236e-03, 3.99150375e-01,\n",
       "       5.09676909e-02, 4.01970618e-01, 6.15305795e-01, 3.20333035e-04,\n",
       "       2.65592802e-01, 3.56997671e-01, 2.82904533e-02, 1.29319875e-01,\n",
       "       5.49111989e-02, 5.14450328e-01, 2.42872174e-01, 3.32652160e-01,\n",
       "       3.41697528e-04, 3.34372480e-01, 1.47687339e-01, 4.32485859e-02,\n",
       "       4.01330751e-01, 1.93004328e-01, 8.36956530e-01, 1.32278552e-01,\n",
       "       3.35676730e-01, 1.71108421e-02, 1.90094690e-01, 6.35057737e-01,\n",
       "       3.16505114e-01, 2.30607575e-01, 1.00000000e+00, 3.16245343e-01,\n",
       "       4.52634241e-01, 2.93777523e-03, 3.34571955e-01, 2.65740898e-01,\n",
       "       4.87417470e-01, 1.85338225e-01, 9.48828971e-02, 4.35783536e-01,\n",
       "       2.34275324e-01, 9.70000000e-01, 1.36861405e-03, 3.00589492e-01,\n",
       "       4.07137837e-03, 1.17076846e-02, 1.54407619e-01, 3.81569671e-01,\n",
       "       3.36222169e-02, 3.48383251e-01, 1.05490417e-01, 4.73165916e-01,\n",
       "       6.46630804e-02, 3.50493013e-03, 1.41987714e-02, 6.19404671e-01,\n",
       "       6.80247396e-01, 4.71331398e-01, 4.07655388e-01, 4.79451704e-01,\n",
       "       2.98129455e-01, 1.27358588e-01, 6.69395765e-01, 2.67443982e-03,\n",
       "       5.35360634e-01, 4.03776688e-01, 3.24030763e-02, 6.73525981e-01,\n",
       "       1.10090390e-02, 2.86276490e-02, 5.93004953e-03, 2.73790035e-01,\n",
       "       1.45962847e-01, 2.35738505e-01, 5.27466604e-01, 4.85771749e-01,\n",
       "       2.40662264e-02, 3.86504738e-01, 1.66453525e-01, 4.84950886e-01,\n",
       "       2.68324941e-01, 3.24488248e-01, 2.96296543e-01, 3.77288894e-01,\n",
       "       1.28562504e-01, 1.58211363e-01, 3.29859457e-01, 3.57219733e-01,\n",
       "       1.40136493e-02, 3.28157747e-01, 2.90215543e-02, 4.73716240e-01,\n",
       "       6.05559499e-03, 1.94127300e-01, 3.06229167e-02, 9.83614891e-02,\n",
       "       4.08272396e-01, 5.04290664e-01, 2.77460609e-02, 3.99185231e-01,\n",
       "       2.30940076e-01, 5.88740514e-01, 7.17308130e-01, 2.30564537e-01,\n",
       "       2.98596872e-01, 2.71392548e-02, 1.51093743e-01, 1.00000000e+00,\n",
       "       3.49402216e-01, 4.52046957e-01, 2.21371856e-01, 3.20333035e-04,\n",
       "       1.37735794e-01, 5.62499073e-01, 2.33321269e-01, 1.37844140e-01,\n",
       "       2.09704539e-01, 7.35999622e-02, 6.34405694e-01, 3.99204834e-01,\n",
       "       6.54455437e-01, 1.00000000e+00, 3.11042307e-01, 4.94104201e-01,\n",
       "       1.00094976e-01, 5.38291237e-01, 3.97959386e-02, 1.48614065e-01,\n",
       "       3.68241969e-01, 2.96888172e-02, 8.91864893e-02, 1.38367673e-01,\n",
       "       3.18215291e-02, 1.81416905e-01, 2.51781968e-01, 1.00000000e+00,\n",
       "       2.30271623e-01, 1.00000000e+00, 3.21654061e-01, 1.81469960e-01,\n",
       "       5.84990580e-01, 3.09548843e-01, 2.25336857e-01, 5.90297415e-01,\n",
       "       5.63911441e-01, 6.50003365e-04, 2.19188608e-01, 3.10667599e-01,\n",
       "       5.38450197e-01, 5.86190128e-01, 3.88921697e-02, 2.68272938e-01,\n",
       "       1.00000000e+00, 1.61663365e-01, 8.47732577e-01, 3.98454305e-01,\n",
       "       2.97974014e-01, 5.94336469e-01, 1.38918419e-01, 3.08773497e-01,\n",
       "       4.73230375e-02, 5.27689198e-01, 1.93422334e-03, 6.22114076e-02,\n",
       "       2.45685427e-01, 4.98389462e-01, 7.04637134e-01, 4.40475037e-01,\n",
       "       3.07292095e-01, 2.14404743e-01, 2.16026794e-01, 3.25390801e-01,\n",
       "       7.91703019e-02, 6.27396477e-01, 2.08797112e-01, 3.61354784e-01,\n",
       "       7.85274730e-01, 5.18729433e-01, 1.02562064e-03, 2.62584668e-01,\n",
       "       2.37255303e-03, 8.86929599e-01, 2.54596704e-02, 2.80251875e-01,\n",
       "       6.14217605e-01, 2.38126818e-01, 3.36509474e-03, 1.88098520e-02,\n",
       "       2.91161680e-03, 2.02021848e-01, 3.42494429e-01, 4.03867918e-01,\n",
       "       4.94660419e-02, 1.90847547e-02, 4.64463484e-01, 3.29492785e-01,\n",
       "       4.45043092e-01, 5.72219222e-01, 1.24727203e-01, 5.73456349e-01,\n",
       "       4.71926125e-01, 1.27838102e-01, 1.64106800e-01, 2.17883643e-01,\n",
       "       2.57994324e-01, 1.96366095e-01, 1.40027287e-03, 4.03806070e-01,\n",
       "       1.26580301e-03, 1.47334316e-01, 2.54990033e-01, 5.67236297e-01,\n",
       "       2.89427228e-02, 2.34943384e-01, 2.31215084e-01, 2.39772202e-01,\n",
       "       5.62693920e-01, 6.74149759e-01, 1.92735405e-03, 3.06476614e-01,\n",
       "       6.88529321e-01, 1.68557209e-03, 3.94891315e-01, 4.16292177e-01,\n",
       "       6.21195823e-01, 2.10697948e-03, 2.85207974e-03, 4.93617576e-01,\n",
       "       2.38759207e-01, 4.40475037e-01, 2.81635124e-01, 1.00000000e+00,\n",
       "       3.70086780e-01, 3.02678224e-01, 6.78992119e-01, 7.50456570e-01,\n",
       "       2.02531548e-01, 2.76366140e-01, 3.72535465e-03, 6.70591478e-01,\n",
       "       1.69806381e-01, 4.40496348e-01, 1.12984575e-01, 5.91375797e-01,\n",
       "       3.37548356e-01, 2.48835876e-01, 2.31246316e-03, 3.89522338e-01,\n",
       "       2.05635669e-01, 1.06825550e-02, 1.04290564e-01, 5.31108533e-02,\n",
       "       2.11209988e-01, 1.00000000e+00, 3.87830282e-01, 4.60615663e-01,\n",
       "       3.65227219e-01, 3.90381985e-01, 7.02240793e-01, 4.64170594e-01,\n",
       "       2.71572642e-01, 3.68643550e-01, 6.19799289e-01, 4.47589763e-01,\n",
       "       3.14030093e-01, 1.96283031e-02, 1.17183488e-01, 3.64825287e-01,\n",
       "       4.44316628e-01, 1.61043397e-01, 6.97972555e-01, 2.75709009e-01,\n",
       "       1.55778039e-03, 1.16114485e-01, 3.13823871e-01, 4.40740254e-01,\n",
       "       1.14953964e-01, 1.65583452e-01, 4.13231035e-01, 7.72950424e-01,\n",
       "       2.05907764e-01, 5.60242484e-01, 2.96679428e-02, 3.32170162e-01,\n",
       "       6.87307017e-01, 6.15305795e-01, 7.40301955e-02, 2.83094461e-03,\n",
       "       4.42280371e-04, 3.32571643e-01, 2.32174600e-01, 1.12789663e-01,\n",
       "       2.92127639e-01, 2.15341320e-01, 2.27813534e-02, 4.41938851e-01,\n",
       "       8.60357744e-01, 3.30137719e-01, 1.23536485e-01, 3.30458389e-01,\n",
       "       6.15492385e-02, 6.96914857e-03, 1.13151729e-01, 3.61889833e-01,\n",
       "       3.54476791e-01, 2.84944634e-01, 3.70144322e-01, 4.47999928e-01,\n",
       "       3.92066193e-01, 2.75297057e-01, 2.80370449e-01, 5.27466604e-01,\n",
       "       1.18156298e-01, 5.55100641e-01, 7.08625318e-01, 1.95497135e-01,\n",
       "       1.39592089e-03, 2.48284873e-01, 1.18605819e-03, 1.00000000e+00,\n",
       "       4.02303881e-01, 3.50289069e-01, 1.18956397e-01, 2.18001494e-01,\n",
       "       6.93593239e-01, 1.30555987e-03, 9.60854241e-01, 3.97140648e-01,\n",
       "       3.76536706e-01, 1.39208143e-01, 3.39951457e-01, 9.61295177e-01,\n",
       "       2.13020771e-01, 2.44171971e-01, 2.95242141e-01, 3.68643759e-01,\n",
       "       4.10538581e-01, 8.27463958e-02, 5.84583595e-01, 2.74057057e-01,\n",
       "       6.15309941e-02, 3.26575668e-02, 4.03486497e-01, 3.15710512e-01,\n",
       "       1.58006118e-01, 3.60677477e-01, 3.96766030e-02, 7.67101867e-01,\n",
       "       2.47184261e-01, 2.39639722e-01, 2.62870603e-01, 3.32489000e-01,\n",
       "       3.22134127e-02, 6.44562634e-02, 3.80747423e-02, 2.31289878e-02,\n",
       "       3.88842341e-01, 3.11731451e-01, 3.59347376e-01, 7.62766005e-01,\n",
       "       9.90000000e-01, 2.06846746e-01, 5.21535919e-01, 2.47255959e-01,\n",
       "       4.62788363e-01, 1.72317132e-01, 2.42389873e-01, 2.28918929e-01,\n",
       "       5.46089350e-01, 1.54266830e-01, 7.84647119e-01, 3.83992173e-01,\n",
       "       4.24543885e-01, 2.50842229e-01, 2.13388523e-01, 2.75891194e-01,\n",
       "       5.96844421e-01, 5.58188159e-01, 1.70950424e-03, 3.63012134e-01,\n",
       "       8.12528128e-02, 1.98236690e-01, 9.05475767e-01, 4.26125562e-03,\n",
       "       5.44632716e-01, 4.24752131e-03, 7.89833366e-01, 2.84938525e-03,\n",
       "       2.14151897e-01, 3.21147929e-01, 3.02795427e-03, 5.75406161e-01,\n",
       "       1.90408550e-01, 1.53601796e-01, 7.23979016e-03, 9.74265499e-01,\n",
       "       7.26625654e-01, 2.11762998e-01, 2.27656338e-03, 9.87590546e-02,\n",
       "       1.69718236e-01, 3.51277030e-02, 1.92561885e-01, 5.34862409e-01,\n",
       "       4.29656856e-01, 2.40774150e-01, 3.02698296e-02, 2.19872790e-03,\n",
       "       1.28063834e-02, 6.03278336e-03, 2.47940252e-02, 2.31015036e-01,\n",
       "       1.36378037e-01, 1.88890747e-01, 2.11354995e-01, 2.23315980e-01,\n",
       "       4.10234726e-01, 2.14581137e-01, 1.74692183e-01, 1.78617512e-01,\n",
       "       1.71136242e-01, 3.69666993e-02, 2.12445831e-01, 1.00000000e+00,\n",
       "       1.74414113e-01, 2.26744709e-01, 3.89522338e-01, 6.33544788e-01,\n",
       "       1.85553948e-01, 5.44778256e-01, 4.30864648e-03, 5.47593614e-03,\n",
       "       1.99333513e-01, 2.92584322e-01, 3.44421706e-01, 7.77316814e-01,\n",
       "       8.66043883e-03, 3.36143899e-02, 2.68450135e-01, 8.38758560e-01,\n",
       "       5.78504045e-02, 7.61725437e-03, 4.00712416e-01, 2.94448496e-01,\n",
       "       1.85287537e-01, 2.52005395e-01, 2.28193563e-01, 1.61776850e-02,\n",
       "       1.55964795e-01, 9.62388775e-01, 5.45052137e-04, 2.39625056e-01,\n",
       "       4.10252865e-02, 1.11716364e-02, 3.68592684e-03, 1.35788186e-01,\n",
       "       1.67257124e-01, 6.87957224e-01, 2.31259196e-01, 2.25623883e-01,\n",
       "       2.07814289e-01, 5.69637685e-01, 9.99265499e-01, 4.81890442e-01,\n",
       "       3.41446224e-01, 3.22956725e-01, 6.01134679e-02, 4.26859897e-01,\n",
       "       7.03038319e-02, 6.06578070e-01, 5.61981020e-03, 3.03126916e-02,\n",
       "       1.62781862e-01, 3.99752987e-01, 6.12260873e-02, 7.46741947e-02,\n",
       "       2.83396327e-02, 2.38073711e-01, 8.47852078e-02, 3.78309392e-01,\n",
       "       7.51351413e-03, 6.99952428e-01, 7.56267420e-03, 2.26375915e-01,\n",
       "       2.08156427e-01, 4.12444485e-01, 8.74722466e-04, 4.52585551e-01,\n",
       "       6.25838507e-01, 9.25084715e-02, 4.85616546e-04, 1.00000000e+00,\n",
       "       1.05618755e-01, 1.98695723e-01, 5.07817809e-01, 5.22973117e-01,\n",
       "       4.37487466e-03, 3.56752616e-01, 1.03371810e-01, 2.53381714e-01,\n",
       "       2.97157276e-01, 3.00924772e-01, 5.40877002e-02, 1.46216868e-01,\n",
       "       5.55122251e-02, 1.61406505e-01, 4.77433477e-01, 2.94790293e-01,\n",
       "       5.32584328e-01, 1.73012600e-01, 5.42490551e-01, 5.70313085e-01,\n",
       "       6.78713245e-01, 1.62442855e-01, 9.03712266e-01, 1.99421331e-01,\n",
       "       2.91057295e-01, 3.21237648e-01, 3.68589363e-01, 5.46484994e-01,\n",
       "       2.58259861e-01, 2.50676654e-02, 4.49647850e-02, 1.39432911e-03,\n",
       "       9.79622642e-01, 9.96250000e-01, 4.11572028e-01, 4.12344448e-04,\n",
       "       2.17392806e-01, 1.05371245e-03, 1.30051488e-02, 1.47265621e-01,\n",
       "       2.37254703e-01, 9.93306216e-02, 1.35264928e-01, 3.88842341e-01,\n",
       "       4.28648651e-03, 1.32123810e-01, 4.93741174e-01, 2.75015116e-01,\n",
       "       2.24192926e-01, 2.59287841e-01, 9.45655374e-01, 3.88721626e-01,\n",
       "       9.42897727e-01, 3.71528099e-01, 1.00000000e+00, 3.31564538e-01,\n",
       "       7.06343461e-02, 1.37737912e-01, 1.54794103e-03, 1.00000000e+00,\n",
       "       3.86951198e-02, 2.92399567e-01, 2.34941337e-01, 2.50849828e-01,\n",
       "       2.60064526e-01, 3.37381508e-01, 1.52970189e-01, 2.11168808e-01,\n",
       "       5.54349385e-01, 1.35997163e-01, 4.85616546e-04, 5.00059776e-01,\n",
       "       2.85207974e-03, 1.32313452e-01, 3.89223675e-01, 1.81753563e-01,\n",
       "       3.17812416e-01, 8.67668849e-03, 2.64198400e-01, 1.88754088e-04,\n",
       "       1.61687473e-02, 8.58322048e-01, 7.11932289e-03, 6.21260305e-01,\n",
       "       1.63836742e-01, 9.63959509e-01, 1.65876726e-01, 7.60019859e-01,\n",
       "       1.17789312e-02, 5.03202122e-01, 9.61857199e-01, 5.87277770e-01,\n",
       "       6.51947958e-02, 2.48142876e-01, 2.32604656e-01, 1.25789558e-01,\n",
       "       1.32465216e-02, 4.42397297e-01, 1.32179052e-02, 4.10120903e-01,\n",
       "       2.30852056e-01, 1.03931479e-01, 2.76720061e-01, 6.29213783e-01,\n",
       "       2.63494244e-01, 2.71451440e-01, 7.01692748e-02, 6.57461570e-01,\n",
       "       4.36626830e-01, 4.29282832e-01, 2.29685825e-01, 3.93952096e-01,\n",
       "       4.12344448e-04, 1.46484011e-01, 3.98405371e-01, 1.85522993e-01,\n",
       "       2.43077063e-01, 1.70007414e-02, 4.62233969e-01, 4.51396613e-03,\n",
       "       2.83318253e-01, 2.40759991e-03, 2.41388209e-01, 1.16163611e-01,\n",
       "       4.42810080e-01, 1.05517063e-01, 1.73190082e-01, 1.42612440e-03,\n",
       "       1.54435397e-03, 1.43799988e-01, 3.20693286e-01, 2.56309022e-01,\n",
       "       5.57025958e-02, 3.91411631e-03, 1.22235933e-01, 5.53674798e-01,\n",
       "       2.96143057e-01, 2.22122599e-01, 1.26805955e-02, 2.72147554e-01,\n",
       "       4.64851352e-01, 1.46566812e-01, 2.66409578e-01, 6.09333951e-03,\n",
       "       1.16455427e-02, 1.33915788e-01, 5.54349385e-01, 3.34127910e-02,\n",
       "       4.00950434e-01, 2.59203484e-01, 2.75944213e-01, 4.72134720e-01,\n",
       "       9.88428363e-01, 4.83410087e-01, 3.74105072e-01, 2.17929932e-01,\n",
       "       5.96789753e-01, 6.51785772e-01, 2.29206569e-01, 7.76791938e-02,\n",
       "       4.50448363e-01, 5.69777821e-01, 1.00000000e+00, 2.00189172e-03,\n",
       "       5.88388603e-01, 9.26435400e-03, 4.80521375e-02, 2.71334798e-01,\n",
       "       3.39322371e-01, 2.99646906e-02, 2.05564416e-02, 3.50186544e-01,\n",
       "       4.76153720e-01, 1.52761763e-01, 1.72362541e-01, 7.95624662e-02,\n",
       "       7.55446055e-01, 9.96250000e-01, 4.71538739e-01, 2.77746513e-01,\n",
       "       9.54901804e-02, 3.81500232e-01, 2.67121143e-01, 1.51923484e-01,\n",
       "       2.15435843e-01, 2.29128704e-01, 1.73889335e-01, 5.00053510e-01,\n",
       "       2.61812677e-01, 5.13094810e-01, 1.08241094e-01, 4.72490201e-01,\n",
       "       2.46480581e-01, 1.00000000e+00, 2.05939573e-01, 6.21692347e-01,\n",
       "       4.56495483e-02, 6.81210411e-01, 1.69881621e-03, 1.68319753e-01,\n",
       "       7.33399840e-01, 2.65242391e-01, 1.18501736e-01, 2.40517613e-01,\n",
       "       5.45225236e-01, 2.30540046e-01, 4.52993273e-01, 8.49796462e-04,\n",
       "       5.65640813e-01, 5.88740514e-01, 1.64027130e-02, 9.79265499e-01,\n",
       "       3.81246930e-01, 4.39765414e-01, 1.09886574e-01, 2.30892437e-01,\n",
       "       6.91974328e-01, 2.41553829e-01, 4.16196914e-01, 2.40504146e-01,\n",
       "       2.61523164e-01, 4.79489118e-01, 2.29413975e-01, 2.39625056e-01,\n",
       "       4.04286471e-01, 5.50976023e-04, 3.58892695e-01, 3.23265325e-01,\n",
       "       1.91093053e-01, 1.34167106e-01, 2.84111426e-03, 4.11636581e-03,\n",
       "       1.93682158e-01, 4.30186004e-01, 6.35065258e-01, 2.36054225e-01,\n",
       "       1.04750009e-03, 2.27615253e-02, 2.64044801e-01, 7.49845817e-01,\n",
       "       4.89321597e-01, 1.42619246e-02, 3.97590413e-01, 2.81758015e-03,\n",
       "       9.99265499e-01, 2.92999246e-02, 2.63068217e-01, 4.55650659e-01,\n",
       "       3.17054645e-01, 5.09465534e-01, 3.79774040e-01, 6.08258254e-01,\n",
       "       6.45907237e-01, 2.97717442e-01, 3.86235716e-01, 9.78428363e-01,\n",
       "       1.24242649e-01, 3.13162151e-02, 3.49515258e-01, 4.88730411e-01,\n",
       "       1.47032319e-01, 1.00000000e+00, 1.31074261e-01, 2.69777721e-01,\n",
       "       5.46483776e-02, 2.86850030e-01, 1.14948388e-01, 2.39102184e-01,\n",
       "       3.29452032e-01, 2.40209303e-01, 5.63414181e-01, 5.87907629e-03,\n",
       "       3.74951637e-01, 1.57143018e-01, 5.23460222e-01, 8.71347674e-01,\n",
       "       7.37168677e-01, 1.67363871e-01, 7.43772111e-01, 5.18424418e-04,\n",
       "       2.17885676e-01, 2.36478197e-01, 1.55565808e-03])"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train on entire dataset and evaluate\n",
    "stack.fit(X, y)\n",
    "y_test = stack.predict_proba(torch_test.X)[:, 1]\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "ef74a392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file\n",
    "submission6 = pd.DataFrame({\n",
    "    'ID': test_IDs,\n",
    "    'Popularity_Type': y_test\n",
    "})\n",
    "submission6.to_csv('submission6.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c9eae9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6241602 , 0.31531761, 0.42883595, 0.74198484, 0.40010006,\n",
       "       0.20997628, 0.34673764, 0.27185327, 0.84339606, 0.42373441,\n",
       "       0.52109343, 0.30227309, 0.45598833, 0.24507934, 0.52147631,\n",
       "       0.5319435 , 0.25587205, 0.05299661, 0.13628264, 0.35320772,\n",
       "       0.36557552, 0.07459991, 0.00968622, 0.01357848, 0.25752431,\n",
       "       0.24320674, 0.38278266, 0.41076695, 0.13211361, 0.16396658,\n",
       "       0.3111333 , 0.439991  , 0.05049661, 0.04381962, 0.1558414 ,\n",
       "       0.20288745, 0.13534647, 0.16050358, 0.32791178, 0.38448624,\n",
       "       0.29626414, 0.01927071, 0.441386  , 0.63048486, 0.01122412,\n",
       "       0.56029852, 0.84926253, 0.00993213, 0.40772233, 0.24045596,\n",
       "       0.72081532, 0.42914388, 0.29507833, 0.81584144, 0.02220808,\n",
       "       0.0493761 , 0.2274584 , 0.36749598, 0.2467408 , 0.45839664,\n",
       "       0.29549265, 0.64973633, 0.01249516, 0.29529083, 0.01021647,\n",
       "       0.29658876, 0.60783898, 0.01054008, 0.07683464, 0.32126685,\n",
       "       0.00954176, 0.14531647, 0.36748052, 0.12386769, 0.52048252,\n",
       "       0.40578396, 0.11708227, 0.03699886, 0.55209917, 0.12802596,\n",
       "       0.31638326, 0.64548725, 0.21661254, 0.36573294, 0.14741251,\n",
       "       0.54098883, 0.37756837, 0.01519203, 0.1452366 , 0.17656898,\n",
       "       0.03011526, 0.36614566, 0.01836252, 0.41468165, 0.44424112,\n",
       "       0.010977  , 0.23966166, 0.48729784, 0.12393061, 0.12844768,\n",
       "       0.02560168, 0.5841152 , 0.25182934, 0.3757984 , 0.01876377,\n",
       "       0.27211595, 0.23162466, 0.03002376, 0.49148314, 0.30003642,\n",
       "       0.7436015 , 0.31192534, 0.30501687, 0.0912604 , 0.20092681,\n",
       "       0.53352879, 0.218434  , 0.27600674, 0.93173022, 0.51212509,\n",
       "       0.50406573, 0.04252046, 0.37371673, 0.20664018, 0.34452465,\n",
       "       0.18271605, 0.26423218, 0.39569188, 0.39412502, 0.87712033,\n",
       "       0.0261812 , 0.28711587, 0.01081488, 0.02572622, 0.16707524,\n",
       "       0.3349028 , 0.07578536, 0.41876761, 0.11036465, 0.50037192,\n",
       "       0.15612886, 0.01476924, 0.12459601, 0.41349656, 0.75051231,\n",
       "       0.56729559, 0.39595606, 0.5625644 , 0.32484883, 0.18475939,\n",
       "       0.81089362, 0.02255754, 0.52925826, 0.40120602, 0.02307186,\n",
       "       0.68337059, 0.10807507, 0.1038927 , 0.04523641, 0.31298935,\n",
       "       0.32100807, 0.24084372, 0.59954507, 0.42243146, 0.01059573,\n",
       "       0.4689974 , 0.17567106, 0.56359685, 0.30055288, 0.30253027,\n",
       "       0.25983151, 0.44788978, 0.17229695, 0.29769442, 0.37886671,\n",
       "       0.41601287, 0.05958769, 0.2299003 , 0.07458952, 0.54381816,\n",
       "       0.09520968, 0.20637533, 0.08484735, 0.06535365, 0.47515551,\n",
       "       0.5240571 , 0.02585054, 0.51919284, 0.24468466, 0.53964344,\n",
       "       0.74198484, 0.34352922, 0.22398722, 0.05265823, 0.23930764,\n",
       "       0.91817509, 0.13659428, 0.38317197, 0.1999672 , 0.00986984,\n",
       "       0.34067859, 0.37987645, 0.33116007, 0.14691996, 0.52890073,\n",
       "       0.16390188, 0.78834765, 0.30285382, 0.70256135, 0.93454666,\n",
       "       0.21711852, 0.58164464, 0.13262213, 0.42669021, 0.01051799,\n",
       "       0.34300722, 0.22695847, 0.08216068, 0.23490126, 0.27443234,\n",
       "       0.08901665, 0.05853279, 0.33129946, 0.91109865, 0.35463016,\n",
       "       0.92309386, 0.33060492, 0.2648664 , 0.50113458, 0.41046541,\n",
       "       0.30414955, 0.45987034, 0.46978656, 0.00953085, 0.31035243,\n",
       "       0.36251084, 0.62519152, 0.58248565, 0.05944798, 0.34942934,\n",
       "       0.92246285, 0.25401211, 0.75606314, 0.44980599, 0.33941306,\n",
       "       0.58198256, 0.2638456 , 0.2369912 , 0.01312464, 0.64643852,\n",
       "       0.01410512, 0.15611525, 0.34766735, 0.5816307 , 0.71678559,\n",
       "       0.44766805, 0.41181616, 0.17842767, 0.2689184 , 0.26485936,\n",
       "       0.31043134, 0.52983343, 0.17513327, 0.37015031, 0.56016848,\n",
       "       0.61277938, 0.0275956 , 0.2926327 , 0.01072748, 0.84076213,\n",
       "       0.016064  , 0.13928132, 0.63204332, 0.59520435, 0.03626919,\n",
       "       0.0241079 , 0.01081006, 0.19605567, 0.24564888, 0.4103581 ,\n",
       "       0.05001088, 0.04285279, 0.36456428, 0.42495664, 0.36891285,\n",
       "       0.59455682, 0.14148579, 0.45795893, 0.31647321, 0.26506227,\n",
       "       0.10114013, 0.25676475, 0.20886216, 0.30377382, 0.03183715,\n",
       "       0.43711726, 0.0305919 , 0.1811241 , 0.03936504, 0.55114327,\n",
       "       0.02444179, 0.28514266, 0.30394491, 0.30086154, 0.32893315,\n",
       "       0.55768324, 0.00955048, 0.28226155, 0.45444459, 0.04223801,\n",
       "       0.3342686 , 0.30081006, 0.5406338 , 0.01664955, 0.01502706,\n",
       "       0.51578969, 0.24647206, 0.44766805, 0.2793055 , 0.9476293 ,\n",
       "       0.35350901, 0.36019665, 0.74713664, 0.70648743, 0.2385961 ,\n",
       "       0.29895831, 0.02881228, 0.67262848, 0.30972634, 0.34673612,\n",
       "       0.17779448, 0.50768984, 0.36201709, 0.29918498, 0.0102848 ,\n",
       "       0.38418232, 0.26737839, 0.01706721, 0.14768212, 0.0183653 ,\n",
       "       0.17102338, 0.93060954, 0.39946006, 0.45029624, 0.36072736,\n",
       "       0.41267588, 0.6433412 , 0.46456422, 0.33909918, 0.37784719,\n",
       "       0.6928078 , 0.43858413, 0.41365222, 0.04573567, 0.30314375,\n",
       "       0.46748325, 0.52667862, 0.2249292 , 0.62627183, 0.17966731,\n",
       "       0.01043941, 0.16745077, 0.26490161, 0.48372754, 0.13492278,\n",
       "       0.32080454, 0.37609936, 0.68615685, 0.42467719, 0.49192968,\n",
       "       0.1279803 , 0.51852622, 0.43753112, 0.44424112, 0.14267587,\n",
       "       0.01527488, 0.02073457, 0.27760992, 0.14656383, 0.15165037,\n",
       "       0.34375431, 0.33244654, 0.0174722 , 0.38950943, 0.7429585 ,\n",
       "       0.48740268, 0.1303425 , 0.39146097, 0.26916707, 0.13245811,\n",
       "       0.31742302, 0.46310074, 0.24648804, 0.42829519, 0.2670851 ,\n",
       "       0.47512329, 0.40847951, 0.30504017, 0.47539482, 0.59954507,\n",
       "       0.30542275, 0.58751213, 0.67404537, 0.25015739, 0.02947629,\n",
       "       0.33770529, 0.00981453, 0.92386696, 0.36147912, 0.33835794,\n",
       "       0.15887917, 0.29519777, 0.70423986, 0.02424092, 0.81339491,\n",
       "       0.31430769, 0.37993589, 0.17010796, 0.35599429, 0.73212816,\n",
       "       0.30471217, 0.26691048, 0.43280662, 0.33012054, 0.41032475,\n",
       "       0.20601914, 0.43970669, 0.35469026, 0.11434484, 0.02808766,\n",
       "       0.48626073, 0.25079832, 0.23553425, 0.45013684, 0.03601328,\n",
       "       0.51260616, 0.31844803, 0.26562739, 0.34485489, 0.45799799,\n",
       "       0.03741602, 0.12038253, 0.06007369, 0.01108752, 0.31618191,\n",
       "       0.43569996, 0.31666794, 0.78896102, 0.9278381 , 0.29502086,\n",
       "       0.42887206, 0.34127927, 0.49194003, 0.24221188, 0.2618274 ,\n",
       "       0.27906581, 0.60441179, 0.0749892 , 0.69008431, 0.32402383,\n",
       "       0.38254373, 0.31408951, 0.34300613, 0.23116678, 0.51306683,\n",
       "       0.43947236, 0.014561  , 0.44600675, 0.09485061, 0.27361676,\n",
       "       0.86393138, 0.05829004, 0.43085684, 0.0268327 , 0.71728916,\n",
       "       0.07817249, 0.3891551 , 0.41016927, 0.01439418, 0.67411286,\n",
       "       0.36466378, 0.13385892, 0.1168378 , 0.87790031, 0.54104311,\n",
       "       0.24344065, 0.16584472, 0.10188198, 0.21008208, 0.13186582,\n",
       "       0.05106476, 0.60641848, 0.34393636, 0.24161392, 0.09174137,\n",
       "       0.02480265, 0.03569908, 0.058193  , 0.04728667, 0.22964818,\n",
       "       0.32761774, 0.38439699, 0.28254572, 0.34013022, 0.58907349,\n",
       "       0.29190794, 0.24757267, 0.21091927, 0.21286611, 0.04789186,\n",
       "       0.23167572, 0.93391719, 0.37183329, 0.26157165, 0.38418232,\n",
       "       0.55924521, 0.2446454 , 0.4643822 , 0.01376312, 0.01243983,\n",
       "       0.18574109, 0.30277351, 0.31999939, 0.52765984, 0.05924658,\n",
       "       0.05863401, 0.36641033, 0.74372872, 0.24451505, 0.01133192,\n",
       "       0.57059366, 0.41644699, 0.23763745, 0.33197798, 0.19301597,\n",
       "       0.02084169, 0.06537464, 0.86864857, 0.0338632 , 0.22798305,\n",
       "       0.14970108, 0.01184193, 0.00871986, 0.20861177, 0.19443676,\n",
       "       0.63046147, 0.27762471, 0.33871034, 0.28294955, 0.43662054,\n",
       "       0.92857534, 0.5513545 , 0.54426422, 0.36918096, 0.06492192,\n",
       "       0.47780337, 0.18553603, 0.4055547 , 0.08109917, 0.01821138,\n",
       "       0.22377853, 0.55981364, 0.21343386, 0.16520716, 0.05484487,\n",
       "       0.39698728, 0.00992822, 0.34030064, 0.0346974 , 0.5317767 ,\n",
       "       0.02413649, 0.26493045, 0.2201238 , 0.3858466 , 0.01448924,\n",
       "       0.54660381, 0.51213564, 0.07643928, 0.0136949 , 0.90418768,\n",
       "       0.01465434, 0.16361032, 0.4030253 , 0.49572399, 0.08408901,\n",
       "       0.51122816, 0.33214402, 0.26392416, 0.39207471, 0.34067201,\n",
       "       0.09283923, 0.15136415, 0.19897429, 0.23423115, 0.37197596,\n",
       "       0.45346878, 0.46701348, 0.16610562, 0.6719282 , 0.59747611,\n",
       "       0.63130392, 0.16380194, 0.60668466, 0.28263008, 0.46845902,\n",
       "       0.31909104, 0.52415814, 0.3811289 , 0.39504643, 0.15199377,\n",
       "       0.12900414, 0.01326861, 0.88664019, 0.88845841, 0.51988521,\n",
       "       0.01300228, 0.26632153, 0.02686746, 0.00975486, 0.12484289,\n",
       "       0.33964375, 0.05599611, 0.32204235, 0.31618191, 0.04080566,\n",
       "       0.22504134, 0.37315011, 0.35991867, 0.35673978, 0.42479598,\n",
       "       0.84871611, 0.42614164, 0.68984958, 0.50797621, 0.84072157,\n",
       "       0.31068221, 0.15316886, 0.27191653, 0.04132155, 0.95587617,\n",
       "       0.15422202, 0.36533199, 0.42244477, 0.44385266, 0.27313151,\n",
       "       0.36597646, 0.1996643 , 0.31137709, 0.55119353, 0.26873774,\n",
       "       0.01993152, 0.52664323, 0.02189138, 0.15128322, 0.24497504,\n",
       "       0.1621989 , 0.32332326, 0.07725231, 0.29546429, 0.01011577,\n",
       "       0.11431487, 0.78015995, 0.02926792, 0.67712928, 0.33892873,\n",
       "       0.80152459, 0.27087405, 0.70825713, 0.02056608, 0.40858726,\n",
       "       0.81896596, 0.52078616, 0.20908069, 0.31370052, 0.32948203,\n",
       "       0.28716277, 0.01028433, 0.68610018, 0.01743908, 0.41432895,\n",
       "       0.26003142, 0.1896669 , 0.2750207 , 0.64516638, 0.20639285,\n",
       "       0.33709464, 0.10442331, 0.67986555, 0.56720001, 0.46382471,\n",
       "       0.36250286, 0.46597416, 0.02742328, 0.17580405, 0.37235598,\n",
       "       0.18162569, 0.26514924, 0.01239192, 0.46457513, 0.06842635,\n",
       "       0.35711088, 0.05156165, 0.2464618 , 0.15719285, 0.41104845,\n",
       "       0.25158775, 0.25859568, 0.01569203, 0.02309118, 0.17576967,\n",
       "       0.31881271, 0.12760442, 0.10201442, 0.00947665, 0.16856482,\n",
       "       0.50850786, 0.37407601, 0.18336304, 0.0274736 , 0.44176106,\n",
       "       0.41060521, 0.39034502, 0.20499903, 0.00983632, 0.0113421 ,\n",
       "       0.42646049, 0.55119353, 0.02739581, 0.55796783, 0.31120432,\n",
       "       0.00890744, 0.42262618, 0.83677785, 0.48833894, 0.51777693,\n",
       "       0.17894941, 0.54329181, 0.84179272, 0.33542531, 0.12270415,\n",
       "       0.48695707, 0.42314856, 0.92620407, 0.02143691, 0.50261088,\n",
       "       0.01225206, 0.04848178, 0.40699446, 0.27222316, 0.02390058,\n",
       "       0.05935012, 0.16177104, 0.46528819, 0.17255928, 0.42908103,\n",
       "       0.18231329, 0.81833989, 0.88845841, 0.47605435, 0.25705939,\n",
       "       0.07029424, 0.40392051, 0.6172741 , 0.20465334, 0.23505716,\n",
       "       0.2599955 , 0.07765041, 0.67336832, 0.33433602, 0.44846292,\n",
       "       0.3610411 , 0.4825421 , 0.33852275, 0.87428477, 0.278866  ,\n",
       "       0.51404074, 0.0184305 , 0.59144798, 0.01627712, 0.29174363,\n",
       "       0.73026403, 0.30799983, 0.17216621, 0.31882818, 0.47990158,\n",
       "       0.32048671, 0.40657732, 0.01465244, 0.40861149, 0.53964344,\n",
       "       0.02923978, 0.93066282, 0.53701871, 0.50880865, 0.24402826,\n",
       "       0.19565665, 0.32112839, 0.1413421 , 0.42161151, 0.43122842,\n",
       "       0.34519701, 0.44865582, 0.25170964, 0.22798305, 0.48220887,\n",
       "       0.02609986, 0.43154967, 0.46925721, 0.25314036, 0.19908391,\n",
       "       0.01939143, 0.03995181, 0.30791148, 0.42919818, 0.5275051 ,\n",
       "       0.33352421, 0.01363224, 0.0182977 , 0.36437816, 0.66647215,\n",
       "       0.43788452, 0.03668798, 0.45451758, 0.04160179, 0.92857534,\n",
       "       0.09937522, 0.27521203, 0.30573668, 0.22225322, 0.36527142,\n",
       "       0.68165727, 0.71720166, 0.33025646, 0.47972376, 0.48388391,\n",
       "       0.90376264, 0.13041037, 0.0168385 , 0.32904727, 0.47896012,\n",
       "       0.16248435, 0.94045286, 0.18003688, 0.3086654 , 0.00924107,\n",
       "       0.37512037, 0.19513679, 0.48421502, 0.47972811, 0.27832246,\n",
       "       0.53930362, 0.10960915, 0.31452946, 0.27498783, 0.65126867,\n",
       "       0.84093242, 0.79570002, 0.22975136, 0.7851056 , 0.01280002,\n",
       "       0.32243086, 0.38948893, 0.01016688])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on test\n",
    "def evaluate_ensemble(ensemble, X):\n",
    "    test_pred = np.zeros(X.numpy().shape[0])\n",
    "    for model in ensemble:\n",
    "        test_pred += model.predict_proba(X)[:, 1]\n",
    "    return test_pred / len(ensemble)\n",
    "\n",
    "# Retrain models on ALL data\n",
    "[model.fit(X, y) for model in ensemble]\n",
    "\n",
    "y_test = evaluate_ensemble(ensemble, torch_test.X)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f331e6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file\n",
    "submission6 = pd.DataFrame({\n",
    "    'ID': test_IDs,\n",
    "    'Popularity_Type': y_test\n",
    "})\n",
    "submission6.to_csv('submission6.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced804d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07881532, 0.07930765, 0.08593754, 0.18899614, 0.08309434,\n",
       "       0.10443603, 0.08074354, 0.14301103, 0.07610199, 0.07955642],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[0].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8729f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_signature</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>track_href</th>\n",
       "      <th>mode</th>\n",
       "      <th>uri</th>\n",
       "      <th>type</th>\n",
       "      <th>track_album_release_date</th>\n",
       "      <th>analysis_url</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>valence</th>\n",
       "      <th>key</th>\n",
       "      <th>tempo</th>\n",
       "      <th>loudness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>Popularity_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2040</td>\n",
       "      <td>0.882</td>\n",
       "      <td>140733.0</td>\n",
       "      <td>0.764</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/7iabz12vAuVQ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>spotify:track:7iabz12vAuVQYyekFIWJxD</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>2024-05-23</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/7iab...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.8860</td>\n",
       "      <td>11.0</td>\n",
       "      <td>140.113</td>\n",
       "      <td>-5.241</td>\n",
       "      <td>0.359000</td>\n",
       "      <td>0.1190</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.779</td>\n",
       "      <td>246960.0</td>\n",
       "      <td>0.640</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/4TsmezEQVSZN...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>spotify:track:4TsmezEQVSZNNPv5RJ65Ov</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>2005-08-29</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/4Tsm...</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>0.4990</td>\n",
       "      <td>7.0</td>\n",
       "      <td>99.017</td>\n",
       "      <td>-8.415</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.770</td>\n",
       "      <td>189707.0</td>\n",
       "      <td>0.597</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/1AtFSBJibfaq...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>spotify:track:1AtFSBJibfaqfiOByQCwZ5</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>2024-06-21</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/1AtF...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>170.022</td>\n",
       "      <td>-4.901</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.3210</td>\n",
       "      <td>0.573</td>\n",
       "      <td>172296.0</td>\n",
       "      <td>0.693</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/18Crh1Nd55lR...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>spotify:track:18Crh1Nd55lRX4MVoJegO1</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/18Cr...</td>\n",
       "      <td>0.004240</td>\n",
       "      <td>0.8370</td>\n",
       "      <td>6.0</td>\n",
       "      <td>150.850</td>\n",
       "      <td>-6.220</td>\n",
       "      <td>0.609000</td>\n",
       "      <td>0.1960</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0315</td>\n",
       "      <td>0.714</td>\n",
       "      <td>274488.0</td>\n",
       "      <td>0.720</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/42Xxh6RlXeZU...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>spotify:track:42Xxh6RlXeZUNtNfbJ6A3D</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>2020-12-24</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/42Xx...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.6960</td>\n",
       "      <td>6.0</td>\n",
       "      <td>113.015</td>\n",
       "      <td>-6.751</td>\n",
       "      <td>0.092200</td>\n",
       "      <td>0.0742</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3859</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0778</td>\n",
       "      <td>0.687</td>\n",
       "      <td>165753.0</td>\n",
       "      <td>0.818</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/7MIhUdNJtaOn...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>spotify:track:7MIhUdNJtaOnDmC5nBC1fb</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>2022-06-17</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/7MIh...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.8860</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125.952</td>\n",
       "      <td>-4.221</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>0.2480</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3860</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.3690</td>\n",
       "      <td>0.611</td>\n",
       "      <td>175059.0</td>\n",
       "      <td>0.710</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/2UsdXWoJI0dD...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>spotify:track:2UsdXWoJI0dDlMAtxeBBg7</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>2024-06-18</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/2Usd...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5520</td>\n",
       "      <td>7.0</td>\n",
       "      <td>85.931</td>\n",
       "      <td>-7.933</td>\n",
       "      <td>0.457000</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3861</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0313</td>\n",
       "      <td>0.550</td>\n",
       "      <td>222073.0</td>\n",
       "      <td>0.412</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/2wbb3Czcii7S...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>spotify:track:2wbb3Czcii7Sv0x5na95w2</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>2022-12-17</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/2wbb...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>11.0</td>\n",
       "      <td>120.897</td>\n",
       "      <td>-8.414</td>\n",
       "      <td>0.366000</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3862</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0476</td>\n",
       "      <td>0.671</td>\n",
       "      <td>248440.0</td>\n",
       "      <td>0.712</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/2fuCquhmrzHp...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>spotify:track:2fuCquhmrzHpu5xcA1ci9x</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>1982-05-03</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/2fuC...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4620</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113.805</td>\n",
       "      <td>-7.815</td>\n",
       "      <td>0.429000</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3863</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.444</td>\n",
       "      <td>143673.0</td>\n",
       "      <td>0.331</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/4VWlYHwHZkBQ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>spotify:track:4VWlYHwHZkBQbyV7wWeaDe</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>2005-03-22</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/4VWl...</td>\n",
       "      <td>0.002530</td>\n",
       "      <td>0.8760</td>\n",
       "      <td>11.0</td>\n",
       "      <td>81.155</td>\n",
       "      <td>-15.307</td>\n",
       "      <td>0.931000</td>\n",
       "      <td>0.0695</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3864 rows  19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      time_signature  speechiness  danceability  duration_ms  energy  \\\n",
       "0                4.0       0.2040         0.882     140733.0   0.764   \n",
       "1                4.0       0.1590         0.779     246960.0   0.640   \n",
       "2                4.0       0.2230         0.770     189707.0   0.597   \n",
       "3                5.0       0.3210         0.573     172296.0   0.693   \n",
       "4                4.0       0.0315         0.714     274488.0   0.720   \n",
       "...              ...          ...           ...          ...     ...   \n",
       "3859             4.0       0.0778         0.687     165753.0   0.818   \n",
       "3860             4.0       0.3690         0.611     175059.0   0.710   \n",
       "3861             4.0       0.0313         0.550     222073.0   0.412   \n",
       "3862             4.0       0.0476         0.671     248440.0   0.712   \n",
       "3863             4.0       0.2250         0.444     143673.0   0.331   \n",
       "\n",
       "                                             track_href  mode  \\\n",
       "0     https://api.spotify.com/v1/tracks/7iabz12vAuVQ...   1.0   \n",
       "1     https://api.spotify.com/v1/tracks/4TsmezEQVSZN...   1.0   \n",
       "2     https://api.spotify.com/v1/tracks/1AtFSBJibfaq...   1.0   \n",
       "3     https://api.spotify.com/v1/tracks/18Crh1Nd55lR...   1.0   \n",
       "4     https://api.spotify.com/v1/tracks/42Xxh6RlXeZU...   1.0   \n",
       "...                                                 ...   ...   \n",
       "3859  https://api.spotify.com/v1/tracks/7MIhUdNJtaOn...   1.0   \n",
       "3860  https://api.spotify.com/v1/tracks/2UsdXWoJI0dD...   1.0   \n",
       "3861  https://api.spotify.com/v1/tracks/2wbb3Czcii7S...   1.0   \n",
       "3862  https://api.spotify.com/v1/tracks/2fuCquhmrzHp...   1.0   \n",
       "3863  https://api.spotify.com/v1/tracks/4VWlYHwHZkBQ...   0.0   \n",
       "\n",
       "                                       uri            type  \\\n",
       "0     spotify:track:7iabz12vAuVQYyekFIWJxD  audio_features   \n",
       "1     spotify:track:4TsmezEQVSZNNPv5RJ65Ov  audio_features   \n",
       "2     spotify:track:1AtFSBJibfaqfiOByQCwZ5  audio_features   \n",
       "3     spotify:track:18Crh1Nd55lRX4MVoJegO1  audio_features   \n",
       "4     spotify:track:42Xxh6RlXeZUNtNfbJ6A3D  audio_features   \n",
       "...                                    ...             ...   \n",
       "3859  spotify:track:7MIhUdNJtaOnDmC5nBC1fb  audio_features   \n",
       "3860  spotify:track:2UsdXWoJI0dDlMAtxeBBg7  audio_features   \n",
       "3861  spotify:track:2wbb3Czcii7Sv0x5na95w2  audio_features   \n",
       "3862  spotify:track:2fuCquhmrzHpu5xcA1ci9x  audio_features   \n",
       "3863  spotify:track:4VWlYHwHZkBQbyV7wWeaDe  audio_features   \n",
       "\n",
       "     track_album_release_date  \\\n",
       "0                  2024-05-23   \n",
       "1                  2005-08-29   \n",
       "2                  2024-06-21   \n",
       "3                  2024-11-08   \n",
       "4                  2020-12-24   \n",
       "...                       ...   \n",
       "3859               2022-06-17   \n",
       "3860               2024-06-18   \n",
       "3861               2022-12-17   \n",
       "3862               1982-05-03   \n",
       "3863               2005-03-22   \n",
       "\n",
       "                                           analysis_url  instrumentalness  \\\n",
       "0     https://api.spotify.com/v1/audio-analysis/7iab...          0.000000   \n",
       "1     https://api.spotify.com/v1/audio-analysis/4Tsm...          0.000766   \n",
       "2     https://api.spotify.com/v1/audio-analysis/1AtF...          0.000000   \n",
       "3     https://api.spotify.com/v1/audio-analysis/18Cr...          0.004240   \n",
       "4     https://api.spotify.com/v1/audio-analysis/42Xx...          0.000000   \n",
       "...                                                 ...               ...   \n",
       "3859  https://api.spotify.com/v1/audio-analysis/7MIh...          0.000000   \n",
       "3860  https://api.spotify.com/v1/audio-analysis/2Usd...          0.000000   \n",
       "3861  https://api.spotify.com/v1/audio-analysis/2wbb...          0.000000   \n",
       "3862  https://api.spotify.com/v1/audio-analysis/2fuC...          0.000000   \n",
       "3863  https://api.spotify.com/v1/audio-analysis/4VWl...          0.002530   \n",
       "\n",
       "      valence   key    tempo  loudness  acousticness  liveness Popularity_Type  \n",
       "0      0.8860  11.0  140.113    -5.241      0.359000    0.1190            High  \n",
       "1      0.4990   7.0   99.017    -8.415      0.000155    0.1010            High  \n",
       "2      0.8750   1.0  170.022    -4.901      0.530000    0.2390            High  \n",
       "3      0.8370   6.0  150.850    -6.220      0.609000    0.1960             Low  \n",
       "4      0.6960   6.0  113.015    -6.751      0.092200    0.0742             Low  \n",
       "...       ...   ...      ...       ...           ...       ...             ...  \n",
       "3859   0.8860   0.0  125.952    -4.221      0.011200    0.2480            High  \n",
       "3860   0.5520   7.0   85.931    -7.933      0.457000    0.1230             Low  \n",
       "3861   0.0986  11.0  120.897    -8.414      0.366000    0.2400             Low  \n",
       "3862   0.4620   2.0  113.805    -7.815      0.429000    0.1030            High  \n",
       "3863   0.8760  11.0   81.155   -15.307      0.931000    0.0695             Low  \n",
       "\n",
       "[3864 rows x 19 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06d7ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
